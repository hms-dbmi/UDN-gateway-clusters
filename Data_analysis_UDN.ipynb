{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis of UDN patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the UDN data resource using the HPDS Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy.stats as st\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "from scipy.stats import kruskal\n",
    "import seaborn as sns\n",
    "import collections as collec\n",
    "import os\n",
    "import xml.etree.ElementTree as ET\n",
    "import collections\n",
    "import operator\n",
    "import pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PicSureHpdsLib\n",
    "import PicSureClient\n",
    "# Connection to the PicSure Client w/ key\n",
    "# token is the individual key given to connect to the resource\n",
    "connection = PicSureClient.Client.connect(\"https://udn.hms.harvard.edu/picsure\", token)\n",
    "adapter = PicSureHpdsLib.Adapter(connection)\n",
    "resource = adapter.useResource(\"8e8c7ed0-87ea-4342-b8da-f939e46bac26\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removekey(d, key):\n",
    "    \"\"\"This functions returns a copy of a dictionnary with a removed key\n",
    "    Parameters: d : dictionnary\n",
    "                key: the key that must be deleted\n",
    "    Returns: copy of dictionnary d without the key \n",
    "    \"\"\"\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CI(a):\n",
    "    \"\"\"Returns the 95% confidence interval for a list/array a\n",
    "    Parameters: a: list or array we want the CI for\n",
    "    Returns: a tuple with 95% confidence interval\n",
    "    \"\"\"\n",
    "    return st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a,nan_policy='omit'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_df(column_head):\n",
    "    \"\"\"Enables the user to download the data as a pandas dataframe indexed by UDN IDs (through API)\n",
    "    Parameters : column_head : string, with the name of the header that will be selected. For example, if the columns that \n",
    "                                should be selected containt \"this string\", then column_head=\"this string\".\n",
    "    Returns: df : dataframe indexed by UDN IDs of the selected columns\n",
    "    \"\"\"\n",
    "    dictionary=resource.dictionary().find(column_head)\n",
    "    query=resource.query()\n",
    "    query.select().add(dictionary.keys())\n",
    "    query.select().add('\\\\000_UDN ID\\\\')\n",
    "    df=query.getResultsDataFrame()\n",
    "    df.set_index(\"\\\\000_UDN ID\\\\\", inplace=True)\n",
    "    query.select().clear()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download phenotypic, status, genomic, primary symptoms and meta- data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = get_data_df(\"\\\\04_Clinical symptoms and physical findings (in HPO, from PhenoTips)\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the phenotypes, and not the prenatal phenotypes\n",
    "columns_to_del=[]\n",
    "for col in list(phenotypes.columns)[1:]:\n",
    "    if \"Prenatal Phenotype\" in col.split('\\\\'):\n",
    "        columns_to_del.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes=phenotypes.drop(columns_to_del,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = get_data_df(\"\\\\13_Status\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes=get_data_df(\"\\\\11_Candidate genes\\\\\")\n",
    "variants=get_data_df(\"\\\\12_Candidate variants\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_symptoms=get_data_df(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_site=get_data_df('\\\\03_UDN Clinical Site\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_history=get_data_df(\"\\\\08_Family history (from PhenoTips)\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natal_history=get_data_df(\"\\\\09_Prenatal and perinatal history (from PhenoTips)\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics=get_data_df(\"\\\\00_Demographics\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics=get_data_df('\\\\14_Disorders (in OMIM, from PhenoTips)\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Age group separation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# break down the analysis in two groups: pediatric (<18 yo) and adults (>=18 yo)\n",
    "adult_patients=list(demographics[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"][demographics[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"]>=18.0].index)\n",
    "pediatric_patients=list(demographics[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"][demographics[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"]<18.0].index)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_phenotypes(phenotypes):\n",
    "    \"\"\"Gets the list of unique phenotypes presented by the patients of the UDN \n",
    "    Parameters: phenotypes : pandas dataframe with the phenotypes\n",
    "    \n",
    "    Returns : patient_phen : dictionary with patients as keys, with values being dictionaries with keys (\"pos\",\"neg\") \n",
    "                             with a list of the positive and negative phenotypes presented by each patient\n",
    "    \"\"\"\n",
    "    header_phen=list(phenotypes)\n",
    "    patient_phen={patient: {\"pos\": [], \"neg\": []} for patient in phenotypes.index.values}\n",
    "    for patient,row in phenotypes.iterrows():\n",
    "        for i,phen in enumerate(row):\n",
    "            if phen==\"Positive\":\n",
    "                if not header_phen[i].split(\"\\\\\")[-2] in patient_phen[patient][\"pos\"]:\n",
    "                    patient_phen[patient][\"pos\"].append(header_phen[i].split(\"\\\\\")[-2])\n",
    "            elif phen==\"Negative\":\n",
    "                if not header_phen[i].split(\"\\\\\")[-2] in patient_phen[patient][\"neg\"]:\n",
    "                    patient_phen[patient][\"neg\"].append(header_phen[i].split(\"\\\\\")[-2])\n",
    "\n",
    "    for patient in patient_phen:\n",
    "        if len(patient_phen[patient][\"pos\"])==0 and len(patient_phen[patient][\"neg\"])==0:\n",
    "            patient_phen=removekey(patient_phen,patient)\n",
    "    return patient_phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_phen=get_patient_phenotypes(phenotypes)\n",
    "patient_phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the evaluation date from patients, and remove the information for patients not in the update \n",
    "# (eval date comes from JSON)\n",
    "patient_eval_date = {}\n",
    "with open(\"patient_eval_date.txt\",\"r\") as evaldate:\n",
    "    lines=evaldate.readlines()\n",
    "    for line in lines:\n",
    "        patient_eval_date[line.split(\" \")[3]]=line.split(\" \")[5].split(\"\\n\")[0]\n",
    "for pat in list(patient_eval_date.keys()):\n",
    "    if not (pat in list(patient_phen)):\n",
    "        patient_eval_date=removekey(patient_eval_date,pat)\n",
    "print(\"Number of patients with no information on eval date : \",collec.Counter([patient_eval_date[pat] for pat in patient_eval_date])[\"None\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of patients evaluated  before 2015, and delete the negative terms for these patients (cf. paper on possible bias)\n",
    "# in the entry of negative terms before 2015\n",
    "list_pat_before_2015=[]\n",
    "for pat in patient_eval_date:\n",
    "    if patient_eval_date[pat]==\"None\":\n",
    "        continue\n",
    "    if int(patient_eval_date[pat].split(\"-\")[0])<=2015:\n",
    "        list_pat_before_2015.append(pat)\n",
    "patient_phen_wo_2015=patient_phen.copy()\n",
    "for pat in list_pat_before_2015:\n",
    "    patient_phen_wo_2015[pat][\"neg\"]=[]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# delete negative terms for patients with over 50 negative terms (cut-off for bias)\n",
    "for pat in patient_phen_wo_2015:\n",
    "    if len(patient_phen_wo_2015[pat][\"neg\"])>=50:\n",
    "        patient_phen_wo_2015[pat][\"neg\"]=[]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breakdown into pediatrics, diagnosed or undiagnosed, and adults, diagnosed or undiagnosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the counts of positive, negative and total HPO terms\n",
    "HPO_terms_pos,HPO_terms_neg={patient: len(patient_phen_wo_2015[patient][\"pos\"]) for patient in patient_phen_wo_2015},{patient: len(patient_phen_wo_2015[patient][\"neg\"]) for patient in patient_phen_wo_2015}\n",
    "HPO_terms={patient: len(patient_phen_wo_2015[patient][\"pos\"])+len(patient_phen_wo_2015[patient][\"neg\"]) for patient in patient_phen_wo_2015}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the counts of positive, negative and total HPO terms for adult population\n",
    "HPO_terms_pos_adult,HPO_terms_neg_adult={patient: len(patient_phen_wo_2015[patient][\"pos\"]) for patient in adult_patients},{patient: len(patient_phen_wo_2015[patient][\"neg\"]) for patient in adult_patients}\n",
    "HPO_terms_adult={patient: len(patient_phen_wo_2015[patient][\"pos\"])+len(patient_phen_wo_2015[patient][\"neg\"]) for patient in adult_patients}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the counts of positive, negative and total HPO terms for pediatric population\n",
    "HPO_terms_pos_pediatric,HPO_terms_neg_pediatric={patient: len(patient_phen_wo_2015[patient][\"pos\"]) for patient in pediatric_patients},{patient: len(patient_phen_wo_2015[patient][\"neg\"]) for patient in pediatric_patients}\n",
    "HPO_terms_pediatric={patient: len(patient_phen_wo_2015[patient][\"pos\"])+len(patient_phen_wo_2015[patient][\"neg\"]) for patient in pediatric_patients}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of diagnosed and undiagnosed patients\n",
    "list_diagnosed=status.loc[status[\"\\\\13_Status\\\\\"] == \"solved\"].index.values.tolist()\n",
    "list_undiagnosed=status.loc[status[\"\\\\13_Status\\\\\"] != \"solved\"].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of diagnosed or undiagnosed patients that have at least one HPO term\n",
    "list_diagnosed_phen=[patient for patient in list_diagnosed if(patient in patient_phen)]\n",
    "list_undiagnosed_phen=[patient for patient in list_undiagnosed if(patient in patient_phen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the lists for breakdown (adults diag and undiag, pediatric diag and undiag)\n",
    "list_adult_diagnosed=[patient for patient in patient_phen if (patient in adult_patients) and (patient in list_diagnosed_phen)]\n",
    "list_adult_undiagnosed=[patient for patient in patient_phen if (patient in adult_patients) and (patient in list_undiagnosed_phen)]\n",
    "list_pediatric_diagnosed=[patient for patient in patient_phen if (patient in pediatric_patients) and (patient in list_diagnosed_phen)]\n",
    "list_pediatric_undiagnosed=[patient for patient in patient_phen if (patient in pediatric_patients) and (patient in list_undiagnosed_phen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"# of adult diagnosed patients\",len(list_adult_diagnosed))\n",
    "print(\"# of adult undiagnosed patients\",len(list_adult_undiagnosed))\n",
    "print(\"# of pediatric diagnosed patients\",len(list_pediatric_diagnosed))\n",
    "print(\"# of pediatric undiagnosed patients\",len(list_pediatric_undiagnosed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframes with the phenotypes of diagnosed or undiagnosed patients that have at least one HPO term\n",
    "phenotypes_diagnosed=phenotypes.loc[list_diagnosed_phen]\n",
    "phenotypes_undiagnosed=phenotypes.loc[list_undiagnosed_phen]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Best phenotypes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_phenotypes(list_patients,patient_phen,nb_of_phen):\n",
    "    \"\"\"Shows the phenotypes the most represented in the UDN gateway for a given community of patients\n",
    "        Parameters: list_patients: list of patients IDs that should be considered\n",
    "                    patient_phen: dictionary with patients as keys, with values being dictionaries with keys (\"pos\",\"neg\") \n",
    "                                 with a list of the positive and negative phenotypes presented by each patient\n",
    "                    nb_of_phen : int, number of best phen to represent\n",
    "        Returns: list_neg_phen : list of ranked best negative associations\n",
    "                 list_pos_phen : list of ranked best positive associations\n",
    "        Shows the nb_of_phen best pos and neg HPO association with % of representation\n",
    "    \"\"\"\n",
    "    list_neg_phen,list_pos_phen=[],[]\n",
    "    neg_phen_w_count,pos_phen_w_count={},{}\n",
    "    for patient in list_patients:\n",
    "        for phen in patient_phen[patient][\"neg\"]:\n",
    "            if not(phen in neg_phen_w_count):\n",
    "                neg_phen_w_count[phen]=1/len(list_patients)*100\n",
    "            else:\n",
    "                neg_phen_w_count[phen]+=1/len(list_patients)*100\n",
    "        for phen in patient_phen[patient][\"pos\"]:\n",
    "            if not(phen in pos_phen_w_count):\n",
    "                pos_phen_w_count[phen]=1/len(list_patients)*100\n",
    "            else:\n",
    "                pos_phen_w_count[phen]+=1/len(list_patients)*100  \n",
    "    sorted_dict_pos=collections.OrderedDict(sorted(pos_phen_w_count.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    sorted_dict_neg=collections.OrderedDict(sorted(neg_phen_w_count.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    print(\"Most highly ranked positive phenotypes\")\n",
    "    for i,key in enumerate(sorted_dict_pos):\n",
    "        print(key,sorted_dict_pos[key])\n",
    "        list_pos_phen.append(sorted_dict_pos[key])\n",
    "        if i>nb_of_phen:\n",
    "            break\n",
    "    print(\"----------------------------------------\")\n",
    "    print(\"Most highly ranked negative phenotypes\")\n",
    "    for i,key in enumerate(sorted_dict_neg):\n",
    "        print(key,sorted_dict_neg[key])\n",
    "        list_neg_phen.append(sorted_dict_neg[key])\n",
    "        if i>nb_of_phen:\n",
    "            break\n",
    "    return list_neg_phen,list_pos_phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# best phenotypes for all patients\n",
    "_,_=get_best_phenotypes(list(patient_phen.keys()),patient_phen,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_composition_phen(list_patients,patient_phen,list_phenotypes,pos_or_neg):\n",
    "    \"\"\"Shows the composition for a certain population of the list of phenotypes given as input\n",
    "    Parameters: list_patients: list of str, UDN IDs to take into consideration \n",
    "                patient_phen: dictionary with patients as keys, with values being dictionaries with keys (\"pos\",\"neg\") \n",
    "                                 with a list of the positive and negative phenotypes presented by each patient\n",
    "                list_phenotypes: list of str, phenotypes to search \n",
    "                pos_or_neg: str, \"pos\" or \"neg\", type of phenotypic association to search for\n",
    "    Returns: None\n",
    "    Shows the % of phenotypes in the list for the given population\n",
    "    \"\"\"\n",
    "    for phen in list_phenotypes:\n",
    "        count=0\n",
    "        for pat in list_patients:\n",
    "            if phen in patient_phen[pat][pos_or_neg]:\n",
    "                count+=1\n",
    "        print(phen,\" : \",count/len(list_patients)*100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for composition for the most represented positive phenotypes\n",
    "list_phenotypes_pos_to_find=[\"Global developmental delay\",\"Seizures\",\"Short stature\",\"Generalized hypotonia\",\"Microcephaly\"]\n",
    "print(\"Adult diagnosed\")\n",
    "get_composition_phen(list_adult_diagnosed,patient_phen,list_phenotypes_pos_to_find,\"pos\")\n",
    "print(\"Adult undiagnosed\")\n",
    "get_composition_phen(list_adult_undiagnosed,patient_phen,list_phenotypes_pos_to_find,\"pos\")\n",
    "print(\"Pediatric diagnosed\")\n",
    "get_composition_phen(list_pediatric_diagnosed,patient_phen,list_phenotypes_pos_to_find,\"pos\")\n",
    "print(\"Pediatric undiagnosed\")\n",
    "get_composition_phen(list_pediatric_undiagnosed,patient_phen,list_phenotypes_pos_to_find,\"pos\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search for composition for the least represented phenotypes\n",
    "list_phenotypes_neg_to_find=[\"Abnormal echocardiogram\",\"EMG abnormality\",\"Hearing impairment\",\"Abnormality of the eye\",\"Abnormality of brain morphology\"]\n",
    "print(\"Adult diagnosed\")\n",
    "get_composition_phen(list_adult_diagnosed,patient_phen,list_phenotypes_neg_to_find,\"neg\")\n",
    "print(\"Adult undiagnosed\")\n",
    "get_composition_phen(list_adult_undiagnosed,patient_phen,list_phenotypes_neg_to_find,\"neg\")\n",
    "print(\"Pediatric diagnosed\")\n",
    "get_composition_phen(list_pediatric_diagnosed,patient_phen,list_phenotypes_neg_to_find,\"neg\")\n",
    "print(\"Pediatric undiagnosed\")\n",
    "get_composition_phen(list_pediatric_undiagnosed,patient_phen,list_phenotypes_neg_to_find,\"neg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the HPO counts into a list of values \n",
    "HPO_list_pos=[HPO_terms_pos[patient] for patient in HPO_terms_pos]\n",
    "HPO_list_neg=[HPO_terms_neg[patient] for patient in HPO_terms_neg]\n",
    "HPO_list=[HPO_terms[patient] for patient in HPO_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the total number of positive, negative, and all HPO terms in the database\n",
    "print(\"# of positive HPO : \",np.sum(HPO_list_pos),\"# of negative HPO : \",np.sum(HPO_list_neg),\"# of total HPO : \",np.sum(HPO_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the HPO counts into a list of values // adult diagnosed \n",
    "HPO_list_pos_adult_diagnosed=[HPO_terms_pos_adult[patient] for patient in list_adult_diagnosed]\n",
    "HPO_list_neg_adult_diagnosed=[HPO_terms_neg_adult[patient] for patient in list_adult_diagnosed]\n",
    "HPO_list_adult_diagnosed=[HPO_terms_adult[patient] for patient in list_adult_diagnosed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the HPO counts into a list of values // adult undiagnosed\n",
    "HPO_list_pos_adult_undiagnosed=[HPO_terms_pos_adult[patient] for patient in list_adult_undiagnosed]\n",
    "HPO_list_neg_adult_undiagnosed=[HPO_terms_neg_adult[patient] for patient in list_adult_undiagnosed]\n",
    "HPO_list_adult_undiagnosed=[HPO_terms_adult[patient] for patient in list_adult_undiagnosed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the HPO counts into a list of values // pediatric diagnosed\n",
    "HPO_list_pos_pediatric_diagnosed=[HPO_terms_pos_pediatric[patient] for patient in list_pediatric_diagnosed]\n",
    "HPO_list_neg_pediatric_diagnosed=[HPO_terms_neg_pediatric[patient] for patient in list_pediatric_diagnosed]\n",
    "HPO_list_pediatric_diagnosed=[HPO_terms_pediatric[patient] for patient in list_pediatric_diagnosed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the HPO counts into a list of values // pediatric undiagnosed\n",
    "HPO_list_pos_pediatric_undiagnosed=[HPO_terms_pos_pediatric[patient] for patient in list_pediatric_undiagnosed]\n",
    "HPO_list_neg_pediatric_undiagnosed=[HPO_terms_neg_pediatric[patient] for patient in list_pediatric_undiagnosed]\n",
    "HPO_list_pediatric_undiagnosed=[HPO_terms_pediatric[patient] for patient in list_pediatric_undiagnosed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stats_HPO_counts(HPO_list,HPO_list_pos,HPO_list_neg):\n",
    "    \"\"\"Show the average and confidence interval for HPO terms for a selected population\n",
    "    Parameters: HPO_list: list of HPO # for selected population\n",
    "                HPO_list_pos: list of positive HPO # for selected population\n",
    "                HPO_list_neg: list of negative HPO # for selected population\n",
    "    Returns: None\n",
    "    Shows the average and CI 95% for HPO counts\n",
    "    \"\"\"\n",
    "    print(\"HPO pos average : \",np.average(HPO_list_pos),\", CI 95% : \",get_CI(HPO_list_pos),\", HPO pos max : \",np.max(HPO_list_pos))\n",
    "    print(\"HPO neg average : \",np.average(HPO_list_neg),\", CI 95% : \",get_CI(HPO_list_neg),\", HPO neg max : \",np.max(HPO_list_neg))\n",
    "    print(\"HPO average : \",np.average(HPO_list),\", CI 95% : \",get_CI(HPO_list),\", HPO max : \",np.max(HPO_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats_HPO_counts(HPO_list,HPO_list_pos,HPO_list_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats_HPO_counts(HPO_list_adult_diagnosed,HPO_list_pos_adult_diagnosed,HPO_list_neg_adult_diagnosed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats_HPO_counts(HPO_list_adult_undiagnosed,HPO_list_pos_adult_undiagnosed,HPO_list_neg_adult_undiagnosed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats_HPO_counts(HPO_list_pediatric_diagnosed,HPO_list_pos_pediatric_diagnosed,HPO_list_neg_pediatric_diagnosed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats_HPO_counts(HPO_list_pediatric_undiagnosed,HPO_list_pos_pediatric_undiagnosed,HPO_list_neg_pediatric_undiagnosed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_distrib_HPO(HPO_list,name):\n",
    "    \"\"\"Plots the distribution of count of HPO terms per patient\n",
    "    Parameters : HPO_list: list of counts for each patient of HPO terms\n",
    "                 name: string, title of the figure\n",
    "    Returns : None\n",
    "    Shows matplotlib plot of distribution of HPO\n",
    "    \"\"\"\n",
    "    distrib=collec.Counter(HPO_list)\n",
    "    X=[key for key in distrib.keys()]\n",
    "    Y=[distrib[key] for key in distrib.keys()]\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.plot(X,Y,\"o\")\n",
    "    plt.xlabel(\"Number of HPO terms\",fontsize=40)\n",
    "    plt.ylabel(\"Count of patients\",fontsize=40)\n",
    "    plt.title(name,fontsize=50)\n",
    "    plt.xticks(fontsize=40)\n",
    "    plt.yticks(fontsize=40)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.axes().set_ylim(None,200)\n",
    "    plt.show()\n",
    "    plt.savefig(\"HPO_terms_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_distrib_HPO(HPO_list,\"Distribution of HPO terms\")\n",
    "show_distrib_HPO(HPO_list_neg,\"Distribution of negative HPO terms\")\n",
    "show_distrib_HPO(HPO_list_pos,\"Distribution of positive HPO terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Negative HPO linked to eval date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "def plot_eval_date_neg_terms(patient_eval_date,patient_phen):\n",
    "    \"\"\"Plots the # of HPO terms according to the evaluation date of patients\n",
    "    Parameters: patient_eval_date : dictionary with patients as keys and evaluation date in str (format \"yyyy-mm-dd\") as value\n",
    "                patient_phen :  dictionary with patients as keys, with values being dictionaries with keys (\"pos\",\"neg\") \n",
    "                             with a list of the positive and negative phenotypes presented by each patient\n",
    "    Returns: None\n",
    "    Shows the plot of # of negative HPO terms vs evaluation date\n",
    "    \"\"\"\n",
    "    pateval=[key for key in list(patient_eval_date.keys()) if patient_eval_date[key]!=\"None\"]\n",
    "    timeeval=pandas.Series([len(patient_phen[pat][\"neg\"]) for pat in pateval],\n",
    "                           index=[date(int(patient_eval_date[pat].split(\"-\")[0]), \n",
    "                                      int(patient_eval_date[pat].split(\"-\")[1]),\n",
    "                                      int(patient_eval_date[pat].split(\"-\")[2])) for pat in pateval])\n",
    "    plt.figure(figsize=(20,15))\n",
    "    g1=timeeval[timeeval>10]\n",
    "    g2=timeeval[timeeval<=10]\n",
    "    g1.plot(style=\".\",color=\"r\",markersize=25)\n",
    "    \"\"\"for i in range(len(timeeval)):\n",
    "        if timeeval[i]>10:\n",
    "            plt.text(timeeval.index[i],timeeval[i]+0.5,pateval[i])\"\"\"\n",
    "    g2.plot(style=\".\",color=\"b\",markersize=25)\n",
    "    plt.title(\"# of negative HPO terms according to evaluation date\")\n",
    "    plt.xlabel(\"Evaluation date\")\n",
    "    plt.ylabel(\"# of HPO neg terms\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_eval_date_neg_terms(patient_eval_date,patient_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# return the list of patients with evaluation prior to 2015, with negative HPO associations >10 and patients with no evaluation\n",
    "# date in resp. pat_prior_2015,pat_high_neg_HPO,pat_no_eval\n",
    "pat_prior_2015,pat_high_neg_HPO,pat_no_eval=[],[],[]\n",
    "for patient in patient_phen:\n",
    "    if patient_eval_date[patient]==\"None\":\n",
    "        pat_no_eval.append(patient)\n",
    "        continue\n",
    "    if int(patient_eval_date[patient].split(\"-\")[0])<=2015:\n",
    "        pat_prior_2015.append([patient,HPO_terms_neg[patient]])\n",
    "    else:\n",
    "        if HPO_terms_neg[patient]>10:\n",
    "            pat_high_neg_HPO.append([patient,HPO_terms_neg[patient],patient_eval_date[patient]])\n",
    "pat_prior_2015,pat_high_neg_HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_neg_terms_by_cs(list_of_cs,patient_phen,patient_eval_date,pat_no_eval,clinical_site,year):\n",
    "    \"\"\"Shows the breakdown (max,min,avg,std) of negative HPO association within the different clinical sites for a given year\n",
    "        Parameters: list_of_cs : list of string of clinical sites\n",
    "                    patient_eval_date : dictionary with patients as keys and evaluation date in str (format \"yyyy-mm-dd\") as value\n",
    "                    patient_phen :  dictionary with patients as keys, with values being dictionaries with keys (\"pos\",\"neg\") \n",
    "                                 with a list of the positive and negative phenotypes presented by each patient\n",
    "                    pat_no_eval : list of patients with no evaluation date associated\n",
    "                    clinical_site: dataframe with the associated clinical sites with patients as index\n",
    "                    year: int, year to be shown\n",
    "        Returns: None\n",
    "        Shows the breakdown per site\n",
    "    \"\"\"\n",
    "    for site in list_of_cs:\n",
    "        print(\"Clinical site \",site)\n",
    "        neg_HPO_site=[]\n",
    "        for patient in patient_phen:\n",
    "            if not( patient in pat_no_eval) and int(patient_eval_date[patient].split(\"-\")[0])==year:\n",
    "                if clinical_site.loc[patient][\"\\\\03_UDN Clinical Site\\\\\"]==site:\n",
    "                    neg_HPO_site.append(HPO_terms_neg[patient])\n",
    "        if len(neg_HPO_site)>0:\n",
    "            print(len(neg_HPO_site))\n",
    "            print(\"Min : \",np.min(neg_HPO_site),\" Max : \",np.max(neg_HPO_site),\" Avg : \",np.average(neg_HPO_site),\" Std : \",np.std(neg_HPO_site))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# year attribute can be changed to plot different years\n",
    "show_neg_terms_by_cs(list_of_cs,patient_phen,patient_eval_date,pat_no_eval,clinical_site,2016)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down list of patients with evaluation prior to 2015\n",
    "with open(\"list_UDNID_HPO_neg.txt\",\"w\") as l:\n",
    "    for i in range(len(pat_prior_2015)):\n",
    "        l.write(\"Patient ID : \"+pat_prior_2015[i][0]+\" # of negative HPO terms : \"+str(pat_prior_2015[i][1])+\"\\n\")\n",
    "l.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write down list of patients with evaluation post 2015 and strictly more than 10 HPO terms\n",
    "with open(\"list_UDNID_HPO_neg_post_2015.txt\",\"w\") as l:\n",
    "    for i in range(len(pat_high_neg_HPO)):\n",
    "        l.write(\"Patient ID : \"+pat_high_neg_HPO[i][0]+\" # of negative HPO terms : \"+str(pat_high_neg_HPO[i][1])+\" Eval date : \"+pat_high_neg_HPO[i][2]+\"\\n\")\n",
    "l.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO large group stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of large groups in the HPO hierarchy\n",
    "large_groups_HPO=[]\n",
    "header_phen=list(phenotypes)[1:]\n",
    "for phen in header_phen:\n",
    "    if not(phen.split(\"\\\\\")[4] in large_groups_HPO):\n",
    "        large_groups_HPO.append(phen.split(\"\\\\\")[4])\n",
    "large_groups_HPO  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the association between unique phenotypes and the large groups they are related to in the HPO hierarchy\n",
    "# list_phenotypes_unique is a dictionary with the phenotypes as keys, and a list of associated large groups as value\n",
    "list_phenotypes_unique={}\n",
    "for phen in header_phen:\n",
    "    if not(phen.split(\"\\\\\")[-2] in list_phenotypes_unique):\n",
    "        list_phenotypes_unique[phen.split(\"\\\\\")[-2]]=[phen.split(\"\\\\\")[4]]\n",
    "    else:\n",
    "        if not(phen.split(\"\\\\\")[4] in list_phenotypes_unique[phen.split(\"\\\\\")[-2]]):\n",
    "            list_phenotypes_unique[phen.split(\"\\\\\")[-2]].append(phen.split(\"\\\\\")[4])\n",
    "list_phenotypes_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_large_groups_HPO_count(large_groups_HPO,patient_phen,list_patients):\n",
    "    \"\"\"Returns the count of HPO terms that belong to a certain group of HPO terms\n",
    "    Parameters: large_groups : list of large groups that belong to the HPO hierarchy\n",
    "                phenotypes : pandas dataframe with the phenotypes\n",
    "    \n",
    "    Returns : group_count : dictionary with keys (\"pos\",\"neg\") that counts the occurrences of positive or negative HPO terms\n",
    "                            for each large group\n",
    "    \"\"\"\n",
    "    header_phen=list(phenotypes)\n",
    "    group_count={\"pos\":{lg: 0 for lg in large_groups_HPO},\"neg\": {lg: 0 for lg in large_groups_HPO}}\n",
    "    for patient in list_patients:\n",
    "        for phen in patient_phen[patient][\"pos\"]:\n",
    "            for lg in list_phenotypes_unique[phen]:\n",
    "                group_count[\"pos\"][lg]+=1\n",
    "        for phen in patient_phen[patient][\"neg\"]:\n",
    "            for lg in list_phenotypes_unique[phen]:\n",
    "                group_count[\"neg\"][lg]+=1\n",
    "    return group_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the HPO occurrences for all patients\n",
    "large_groups_HPO_count=get_large_groups_HPO_count(large_groups_HPO,patient_phen_wo_2015,list(patient_phen_wo_2015.keys()))\n",
    "print(\"Total : neg : \",np.sum(list(large_groups_HPO_count[\"neg\"].values())),\" pos : \",np.sum(list(large_groups_HPO_count[\"pos\"].values())))\n",
    "large_groups_HPO_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the count of large groups for positive and negative terms of adult patients\n",
    "large_groups_HPO_count_adult=get_large_groups_HPO_count(large_groups_HPO,patient_phen_wo_2015,adult_patients)\n",
    "print(\"Total : neg : \",np.sum(list(large_groups_HPO_count_adult[\"neg\"].values())),\" pos : \",np.sum(list(large_groups_HPO_count_adult[\"pos\"].values())))\n",
    "large_groups_HPO_count_adult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the count of large groups for positive and negative terms of pediatric patients\n",
    "large_groups_HPO_count_pediatric=get_large_groups_HPO_count(large_groups_HPO,patient_phen_wo_2015,pediatric_patients)\n",
    "print(\"Total : neg : \",np.sum(list(large_groups_HPO_count_pediatric[\"neg\"].values())),\" pos : \",np.sum(list(large_groups_HPO_count_pediatric[\"pos\"].values())))\n",
    "large_groups_HPO_count_pediatric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison HPO and Primary Symptoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_between_PS_HPO(patient_phen,primary_symptoms,list_phenotypes_unique):\n",
    "    \"\"\"Returns the link count of occurrence of a certain HPO large group for patients with a certain primary symptom\n",
    "    Parameters : patient_phen :  dictionary with patients as keys, with values being dictionaries with keys (\"pos\",\"neg\") \n",
    "                                 with a list of the positive and negative phenotypes presented by each patient \n",
    "                 primary_symptoms: dataframe with UDN IDs as index, and list of primary symptoms reported \n",
    "                 list_phenotypes_unique: dictionary of link between phenotypes and the large groups they are linked\n",
    "                 to in the HPO hierarchy\n",
    "    Returns : dictionary with keys (\"pos\",\"neg\") that contain a dictionary with the primary symptoms as keys and a dictionary \n",
    "              with the count for every large group of HPO hierarchy of occurrences as value\n",
    "    \"\"\"\n",
    "    link_PS_HPO={\"pos\": {}, \"neg\": {}}\n",
    "    for patient in patient_phen:\n",
    "        ps=list(primary_symptoms.loc[patient])[1]\n",
    "        if not(ps in link_PS_HPO[\"pos\"]):\n",
    "            link_PS_HPO[\"pos\"][ps]={}\n",
    "        if not(ps in link_PS_HPO[\"neg\"]):\n",
    "            link_PS_HPO[\"neg\"][ps]={}\n",
    "        for phen in patient_phen[patient][\"pos\"]:\n",
    "            for lg in list_phenotypes_unique[phen]:\n",
    "                if lg in link_PS_HPO[\"pos\"][ps]:\n",
    "                    link_PS_HPO[\"pos\"][ps][lg]+=1\n",
    "                else:\n",
    "                    link_PS_HPO[\"pos\"][ps][lg]=1\n",
    "        for phen in patient_phen[patient][\"neg\"]:\n",
    "            for lg in list_phenotypes_unique[phen]:\n",
    "                if lg in link_PS_HPO[\"neg\"][ps]:\n",
    "                    link_PS_HPO[\"neg\"][ps][lg]+=1\n",
    "                else:\n",
    "                    link_PS_HPO[\"neg\"][ps][lg]=1\n",
    "    return link_PS_HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the links between the primary symptoms and the HPO large groups\n",
    "link_PS_HPO=get_link_between_PS_HPO(patient_phen,primary_symptoms,list_phenotypes_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the ranked HPO groups for each primary symptom \n",
    "for ps in link_PS_HPO[\"pos\"]:\n",
    "    print(\"Primary symptom \",ps)\n",
    "    print(\"-------------------------------------------\")\n",
    "    if type(ps)==float:\n",
    "        continue\n",
    "    lg_list=list(link_PS_HPO[\"pos\"][ps])\n",
    "    val=[link_PS_HPO[\"pos\"][ps][lg] for lg in lg_list]\n",
    "    indsort=np.argsort(val)[::-1]\n",
    "    lg_list=np.array(lg_list)[indsort]\n",
    "    val=np.array(val)[indsort]\n",
    "    for i in range(len(indsort)):\n",
    "        print(lg_list[i],val[i])\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of demographics and clinical site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframes for patients with at least one phenotype, for adult or pediatric, diagnosed and undiagnosed \n",
    "demographics = demographics.loc[list(patient_phen)]\n",
    "demographics_adult_diagnosed = demographics.loc[list_adult_diagnosed]\n",
    "demographics_adult_undiagnosed = demographics.loc[list_adult_undiagnosed]\n",
    "demographics_pediatric_diagnosed = demographics.loc[list_pediatric_diagnosed]\n",
    "demographics_pediatric_undiagnosed = demographics.loc[list_pediatric_undiagnosed]\n",
    "clinical_site = clinical_site.loc[list(patient_phen)]\n",
    "clinical_site_adult_diagnosed = clinical_site.loc[list_adult_diagnosed]\n",
    "clinical_site_adult_undiagnosed = clinical_site.loc[list_adult_undiagnosed]\n",
    "clinical_site_pediatric_diagnosed = clinical_site.loc[list_pediatric_diagnosed]\n",
    "clinical_site_pediatric_undiagnosed = clinical_site.loc[list_pediatric_undiagnosed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of clinical sites for patients with at least one phenotype, for adult or pediatric, diagnosed and undiagnosed\n",
    "cscount = clinical_site.groupby('\\\\03_UDN Clinical Site\\\\')['Patient ID'].nunique()\n",
    "cscount_ad = clinical_site_adult_diagnosed.groupby('\\\\03_UDN Clinical Site\\\\')['Patient ID'].nunique()\n",
    "cscount_and = clinical_site_adult_undiagnosed.groupby('\\\\03_UDN Clinical Site\\\\')['Patient ID'].nunique()\n",
    "cscount_pd = clinical_site_pediatric_diagnosed.groupby('\\\\03_UDN Clinical Site\\\\')['Patient ID'].nunique()\n",
    "cscount_pnd = clinical_site_pediatric_undiagnosed.groupby('\\\\03_UDN Clinical Site\\\\')['Patient ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clinical site count general\")\n",
    "print(cscount)\n",
    "print(\"Clinical site count adult diagnosed\")\n",
    "print(cscount_ad)\n",
    "print(\"Clinical site count adult undiagnosed\")\n",
    "print(cscount_and)\n",
    "print(\"Clinical site count pediatric diagnosed\")\n",
    "print(cscount_pd)\n",
    "print(\"Clinical site count pediatric undiagnosed\")\n",
    "print(cscount_pnd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count eth for general \",collec.Counter(demographics['\\\\00_Demographics\\\\Ethnicity\\\\']))\n",
    "print(\"Count eth for adult diagnosed \",collec.Counter(demographics_adult_diagnosed['\\\\00_Demographics\\\\Ethnicity\\\\']))\n",
    "print(\"Count eth for adult undiagnosed \",collec.Counter(demographics_adult_undiagnosed['\\\\00_Demographics\\\\Ethnicity\\\\']))\n",
    "print(\"Count eth for pediatric diagnosed \",collec.Counter(demographics_pediatric_diagnosed['\\\\00_Demographics\\\\Ethnicity\\\\']))\n",
    "print(\"Count eth for pediatric undiagnosed \",collec.Counter(demographics_pediatric_undiagnosed['\\\\00_Demographics\\\\Ethnicity\\\\']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count race for general \",collec.Counter(demographics[\"\\\\00_Demographics\\\\Race\\\\\"]))\n",
    "print(\"Count race for adult diagnosed \",collec.Counter(demographics_adult_diagnosed[\"\\\\00_Demographics\\\\Race\\\\\"]))\n",
    "print(\"Count race for adult undiagnosed \",collec.Counter(demographics_adult_undiagnosed[\"\\\\00_Demographics\\\\Race\\\\\"]))\n",
    "print(\"Count race for pediatric diagnosed \",collec.Counter(demographics_pediatric_diagnosed[\"\\\\00_Demographics\\\\Race\\\\\"]))\n",
    "print(\"Count race for pediatric undiagnosed \",collec.Counter(demographics_pediatric_undiagnosed[\"\\\\00_Demographics\\\\Race\\\\\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistics for demographics for adult all patients\n",
    "demographics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistics for demographics for adult diagnosed patients\n",
    "demographics_adult_diagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistics for demographics for adult undiagnosed patients\n",
    "demographics_adult_undiagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistics for demographics, for pediatric diagnosed patients\n",
    "demographics_pediatric_diagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistics for demographics, for pediatric undiagnosed patients\n",
    "demographics_pediatric_undiagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_age_distrib(demographics):\n",
    "    \"\"\"Show the age distribution in the network\n",
    "    Parameters: demographics: pd dataframe, with columns containing age at symptom onset\n",
    "    Returns: None\n",
    "    Shows the age distribution as a plot\n",
    "    \"\"\"\n",
    "    X=list(collec.Counter(demographics[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"].fillna(0)))\n",
    "    Y=[collec.Counter(demographics[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"])[i] for i in X]\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.plot(X,Y)\n",
    "    plt.title(\"Age at symptom onset (in y) distribution in UDN\")\n",
    "    plt.xlabel(\"Age at symptom onset (in y)\")\n",
    "    plt.ylabel(\"Count of patients\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_age_distrib(demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the gender count, for adult or pediatric, diagnosed and undiagnosed\n",
    "gender_count = demographics.groupby(\"\\\\00_Demographics\\\\Gender\\\\\")['Patient ID'].nunique()\n",
    "gender_count_ad = demographics_adult_diagnosed.groupby(\"\\\\00_Demographics\\\\Gender\\\\\")['Patient ID'].nunique()\n",
    "gender_count_and = demographics_adult_undiagnosed.groupby(\"\\\\00_Demographics\\\\Gender\\\\\")['Patient ID'].nunique()\n",
    "gender_count_pd = demographics_pediatric_diagnosed.groupby(\"\\\\00_Demographics\\\\Gender\\\\\")['Patient ID'].nunique()\n",
    "gender_count_pnd = demographics_pediatric_undiagnosed.groupby(\"\\\\00_Demographics\\\\Gender\\\\\")['Patient ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gender count general\")\n",
    "print(gender_count)\n",
    "print(\"Gender count adult diagnosed\")\n",
    "print(gender_count_ad)\n",
    "print(\"Gender count adult undiagnosed\")\n",
    "print(gender_count_and)\n",
    "print(\"Gender count pediatric diagnosed\")\n",
    "print(gender_count_pd)\n",
    "print(\"Gender count pediatric undiagnosed\")\n",
    "print(gender_count_pnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Distribution of HPO terms according to clinical site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the distribution of HPO terms within the clinical sites, with min, max, avg and std, as well as solved cases\n",
    "list_of_cs=list(clinical_site[\"\\\\03_UDN Clinical Site\\\\\"].unique())\n",
    "for site in list_of_cs:\n",
    "    print(\"Clinical site \",site)\n",
    "    pat_in_site=list(clinical_site[clinical_site[\"\\\\03_UDN Clinical Site\\\\\"]==site].index)\n",
    "    print(\"# of patients in site : \",len(pat_in_site))\n",
    "    list_HPO_site=[]\n",
    "    diag_cases=[]\n",
    "    for pat in pat_in_site:\n",
    "        list_HPO_site.append(HPO_terms[pat])\n",
    "        if pat in list_diagnosed_phen:\n",
    "            diag_cases.append(pat)\n",
    "    print(\"Min : \",np.min(list_HPO_site),\" Max : \",np.max(list_HPO_site),\" Avg : \",np.average(list_HPO_site),\" Std : \",np.std(list_HPO_site))\n",
    "    print(\"Percentage solved cases : \",len(diag_cases)/len(pat_in_site)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of primary symptoms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the primary symptoms for patients with at least one phenotype, for adult or pediatric, diagnosed and undiagnosed\n",
    "primary_symptoms = primary_symptoms.loc[list(patient_phen)]\n",
    "primary_symptoms_ad = primary_symptoms.loc[list_adult_diagnosed]\n",
    "primary_symptoms_and = primary_symptoms.loc[list_adult_undiagnosed]\n",
    "primary_symptoms_pd = primary_symptoms.loc[list_pediatric_diagnosed]\n",
    "primary_symptoms_pnd = primary_symptoms.loc[list_pediatric_undiagnosed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the primary symptom count, for adult or pediatric, diagnosed and undiagnosed\n",
    "pscount = primary_symptoms.groupby(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")['Patient ID'].nunique()\n",
    "pscount_ad = primary_symptoms_ad.groupby(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")['Patient ID'].nunique()\n",
    "pscount_and = primary_symptoms_and.groupby(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")['Patient ID'].nunique()\n",
    "pscount_pd = primary_symptoms_pd.groupby(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")['Patient ID'].nunique()\n",
    "pscount_pnd = primary_symptoms_pnd.groupby(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")['Patient ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Primary symptom count general\")\n",
    "print(pscount)\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Primary symptom count adult diagnosed\")\n",
    "print(pscount_ad)\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Primary symptom count adult undiagnosed\")\n",
    "print(pscount_and)\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Primary symptom count pediatric diagnosed\")\n",
    "print(pscount_pd)\n",
    "print(\"---------------------------------------------\")\n",
    "print(\"Primary symptom count pediatric undiagnosed\")\n",
    "print(pscount_pnd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get family history for patients with at least one phenotype, diagnosed or undiagnosed\n",
    "family_history = family_history.loc[list(patient_phen)]\n",
    "family_history_d = family_history.loc[list_diagnosed_phen]\n",
    "family_history_nd = family_history.loc[list_undiagnosed_phen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of affected relatives, for diagnosed or undiagnosed\n",
    "fhcount = family_history.groupby(\"\\\\08_Family history (from PhenoTips)\\\\Affected Relatives\\\\\")['Patient ID'].nunique()\n",
    "fhcount_d = family_history_d.groupby(\"\\\\08_Family history (from PhenoTips)\\\\Affected Relatives\\\\\")['Patient ID'].nunique()\n",
    "fhcount_nd = family_history_nd.groupby(\"\\\\08_Family history (from PhenoTips)\\\\Affected Relatives\\\\\")['Patient ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Affected relatives count general\")\n",
    "print(fhcount)\n",
    "print(\"Affected relatives count diagnosed\")\n",
    "print(fhcount_d)\n",
    "print(\"Affected relatives count undiagnosed\")\n",
    "print(fhcount_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get natal history for patients with at least one phenotype\n",
    "natal_history = natal_history.loc[list(patient_phen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values by NaN\n",
    "natal_history = natal_history.replace(0, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get natal history for pediatric and adult patients\n",
    "natal_history_adult=natal_history.loc[adult_patients]\n",
    "natal_history_pediatric=natal_history.loc[pediatric_patients]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natal_history.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot characteristics for natal history for entire network\n",
    "natal_history.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot characteristics for natal history for adult patients\n",
    "natal_history_adult.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot characteristics for natal history for pediatric patients\n",
    "natal_history_pediatric.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of positive or negative occurrences for any given phenotype. Ex: if count_pos_phen[i]=3, \n",
    "# then there are three patients in the database that are positive for the phenotype header_phen[i]\n",
    "count_pos_phen,count_neg_phen=[0 for i in range(1,phenotypes.shape[1])],[0 for i in range(1,phenotypes.shape[1])]\n",
    "for i in range(1,phenotypes.shape[1]):\n",
    "    cts=phenotypes.iloc[:,i].value_counts()\n",
    "    keys=cts.keys().tolist()\n",
    "    for j in range(len(keys)):\n",
    "        if keys[j]==\"Positive\":\n",
    "            count_pos_phen[i-1]=cts[j]\n",
    "        elif keys[j]==\"Negative\":\n",
    "            count_neg_phen[i-1]=cts[j]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collec.Counter(family_history[\"\\\\08_Family history (from PhenoTips)\\\\Consanguinity\\\\\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_phenotypes_consang(patient_phen,family_history):\n",
    "    \"\"\"Gives the list of overrepresented phenotypes in the consanguineous community\n",
    "    Parameters : patient_phen :  dictionary with patients as keys, with values being dictionaries with keys (\"pos\",\"neg\") \n",
    "                                 with a list of the positive and negative phenotypes presented by each patient\n",
    "                 family_history : dataframe with family history \n",
    "    Returns : dictionary with the count for positive or negative phenotypes of patients presenting such phenotype\n",
    "    Shows the ranked 10 best phenotypes, for positive and negative as well as the Mann Whitney U stats for difference in \n",
    "    distribution between the consanguineous and general community\n",
    "    \"\"\"\n",
    "    count_phenotype_consang={\"pos\": {}, \"neg\": {}}\n",
    "    csgcount=0\n",
    "    for patient in list(patient_phen):\n",
    "        consang = family_history.loc[patient][2]\n",
    "        if consang==True:\n",
    "            csgcount+=1\n",
    "            for phen_pos in patient_phen[patient][\"pos\"]:\n",
    "                if not(phen_pos in count_phenotype_consang[\"pos\"]):\n",
    "                    count_phenotype_consang[\"pos\"][phen_pos]=1\n",
    "                else:\n",
    "                    count_phenotype_consang[\"pos\"][phen_pos]+=1\n",
    "            for phen_neg in patient_phen[patient][\"neg\"]:\n",
    "                if not(phen_neg in count_phenotype_consang[\"neg\"]):\n",
    "                    count_phenotype_consang[\"neg\"][phen_neg]=1\n",
    "                else:\n",
    "                    count_phenotype_consang[\"neg\"][phen_neg]+=1\n",
    "    \n",
    "    phen_pos_list=list(count_phenotype_consang[\"pos\"])\n",
    "    val=[count_phenotype_consang[\"pos\"][phen] for phen in phen_pos_list]\n",
    "    indsort=np.argsort(val)[::-1]\n",
    "    phen_pos_list=np.array(phen_pos_list)[indsort][:18]\n",
    "    val=np.array(val)[indsort][:18]\n",
    "    print('Best positive phenotypes')\n",
    "    comp_mw_true=[]\n",
    "    for j,phen in enumerate(phen_pos_list):\n",
    "        for i,p in enumerate(list(phenotypes)[1:]):\n",
    "            if p.split(\"\\\\\")[-2]==phen:\n",
    "                print(phen,\"consang % \",val[j]/csgcount*100,\" general % \",count_pos_phen[i]/phenotypes.shape[0]*100)\n",
    "                comp_mw_true.append(count_pos_phen[i]/phenotypes.shape[0]*100)\n",
    "                break\n",
    "    print(\"Mann-Whitney pos : \")\n",
    "    print(\"Medians : \",np.median(np.multiply(val,100/csgcount)),np.median(comp_mw_true))\n",
    "    print(mannwhitneyu(np.multiply(val,100/csgcount),comp_mw_true))\n",
    "    phen_neg_list=list(count_phenotype_consang[\"neg\"])\n",
    "    val=[count_phenotype_consang[\"neg\"][phen] for phen in phen_neg_list]\n",
    "    indsort=np.argsort(val)[::-1]\n",
    "    phen_neg_list=np.array(phen_neg_list)[indsort][:10]\n",
    "    val=np.array(val)[indsort][:10]\n",
    "    print('Best negative phenotypes')\n",
    "    comp_mw_true=[]\n",
    "    for j,phen in enumerate(phen_neg_list):\n",
    "        for i,p in enumerate(list(phenotypes)[1:]):\n",
    "            if p.split(\"\\\\\")[-2]==phen:\n",
    "                print(phen,\"consang % \",val[j]/csgcount*100,\" general % \",count_neg_phen[i]/phenotypes.shape[0]*100)\n",
    "                comp_mw_true.append(count_neg_phen[i]/phenotypes.shape[0]*100)\n",
    "                break\n",
    "    print(\"Mann-Whitney neg : \")\n",
    "    print(\"Medians : \",np.median(np.multiply(val,100/csgcount)),np.median(comp_mw_true))\n",
    "    print(mannwhitneyu(np.multiply(val,100/csgcount),comp_mw_true))\n",
    "    print(\"How many consang ?\",csgcount)\n",
    "    return count_phenotype_consang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_phenotype_consang=get_best_phenotypes_consang(patient_phen,family_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat_age is the maternal age without the NaN values\n",
    "mat_age=np.array(natal_history[\"\\\\09_Prenatal and perinatal history (from PhenoTips)\\\\Maternal Age\\\\\"])\n",
    "isnan_mat=np.isnan(mat_age)\n",
    "mat_age=mat_age[[not(isnan_mat[i]) for i in range(len(isnan_mat))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pat_age is the paternal age without the NaN values\n",
    "pat_age=np.array(natal_history[\"\\\\09_Prenatal and perinatal history (from PhenoTips)\\\\Paternal Age\\\\\"])\n",
    "isnan_pat=np.isnan(pat_age)\n",
    "pat_age=pat_age[[not(isnan_pat[i]) for i in range(len(isnan_pat))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of paternal age in the US in 2009 (cf. article)\n",
    "USA_dist_pat=[4.7,17.7,25.1,26.6,16.3,6.7,2.1,0.8]\n",
    "tranches_pat=[\"0-19\",\"20-24\",\"25-29\",\"30-34\",\"35-39\",\"40-44\",\"44-50\",\">50\"]\n",
    "boundaries_pat=[[0,19],[20,24],[25,29],[30,34],[35,39],[40,44],[44,50],[50,100]]\n",
    "\n",
    "# distribution of maternal age in the US in 2009 (cf. article)\n",
    "USA_dist_mat = [3.1,6.9,24.4,28.2,23.1,11.5,2.8]\n",
    "tranches_mat=[\"0-18\",\"19\",\"20-24\",\"25-29\",\"30-34\",\"35-39\",\">39\"]\n",
    "boundaries_mat=[[0,18],[19,19],[20,24],[25,29],[30,34],[35,39],[39,100]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distrib_age(parent_age, known_dist,tranches,boundaries,mat_or_pat):\n",
    "    \"\"\"Shows the distribution of maternal age compared between UDN and the US in 2009\n",
    "    Parameters : parent_age: array of parental age in the UDN database\n",
    "                 known_dist: list, known distribution of parental age for age groups given in splits\n",
    "                 tranches: list of str, age groups that correspond to the known distribution \n",
    "                 boundaries: array of 2-D arrays, with the boundaries in int corresponding to the splits given in tranches\n",
    "                 mat_or_pat: \"mat\" or \"pat\", for maternal or paternal age\n",
    "    Returns: dictionary with age distribution in the UDN \n",
    "    Shows a joint plot of UDN distribution and known distribution of maternal age\n",
    "    \"\"\"\n",
    "    count_age={}\n",
    "    for age in parent_age:\n",
    "        if age in count_age:\n",
    "            count_age[age]+=1\n",
    "        else:\n",
    "            count_age[age]=1\n",
    "    distrib_age=[0 for i in range(len(tranches))]\n",
    "    for age in count_age:\n",
    "        for i in range(len(boundaries)):\n",
    "            if age>=boundaries[i][0] and age<=boundaries[i][1]:\n",
    "                distrib_age[i]+=count_age[age]/len(parent_age)*100\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.plot(tranches,distrib_age,'b',label=\"Distribution in UDN\")\n",
    "    plt.plot(tranches,known_dist,'r',label=\"Distribution in USA in 2009\")\n",
    "    plt.xlabel(mat_or_pat+\" age at birth\",fontsize=20)\n",
    "    plt.ylabel(\"Distribution in UDN vs USA in 2009 (%)\",fontsize=20)\n",
    "    plt.xticks(fontsize=15)\n",
    "    plt.yticks(fontsize=15)\n",
    "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.,fontsize=20)\n",
    "    plt.show()\n",
    "    return distrib_age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_age_mat=distrib_age(mat_age,USA_dist_mat,tranches_mat,boundaries_mat,\"Maternal\")\n",
    "\n",
    "ttest_ind(dist_age_mat,USA_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Paternal age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_age_pat=distrib_age(pat_age,USA_dist_pat,tranches_pat,boundaries_pat,\"Paternal\")\n",
    "\n",
    "ttest_ind(dist_age_pat,USA_dist_pat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cut-off for \"old\" vs \"young\" parents is 35 y/o, cut the analysis according to that\n",
    "paternal_age_df=natal_history[\"\\\\09_Prenatal and perinatal history (from PhenoTips)\\\\Paternal Age\\\\\"].dropna()\n",
    "patients_with_pat_age=list(paternal_age_df.index)\n",
    "old_pat_age=[patients_with_pat_age[i] for i in range(len(patients_with_pat_age)) if paternal_age_df.loc[patients_with_pat_age[i]]>35]\n",
    "young_pat_age=[patients_with_pat_age[i] for i in range(len(patients_with_pat_age)) if paternal_age_df.loc[patients_with_pat_age[i]]<=35]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographics description for all patients having reported paternal age\n",
    "demographics.loc[old_pat_age+young_pat_age].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographics for patients with paternal age >=35\n",
    "demographics.loc[old_pat_age].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# demographics for patients with paternal age <35\n",
    "demographics.loc[young_pat_age].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann Whitney U test for diff between young and old paternal age for Age at UDN evaluation\n",
    "mannwhitneyu(list(demographics[\"\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\\"].loc[young_pat_age]),list(demographics[\"\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\\"].loc[old_pat_age]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann Whitney U test for diff between young and old paternal age for Age at UDN evaluation\n",
    "mannwhitneyu(list(demographics[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"].loc[young_pat_age]),list(demographics[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"].loc[old_pat_age]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of patient phenotypes for patients with old, young paternal age and all those having reported paternal age\n",
    "old_pat_patient_phen,young_pat_patient_phen,all_pat_patient_phen={},{},{}\n",
    "for pat in patient_phen:\n",
    "    if pat in old_pat_age:\n",
    "        old_pat_patient_phen[pat]=patient_phen[pat]\n",
    "        all_pat_patient_phen[pat]=patient_phen[pat]\n",
    "    if pat in young_pat_age:\n",
    "        young_pat_patient_phen[pat]=patient_phen[pat]\n",
    "        all_pat_patient_phen[pat]=patient_phen[pat]\n",
    "len(old_pat_patient_phen),len(young_pat_patient_phen),len(all_pat_patient_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_phenotype_pat(patient_phen):\n",
    "    \"\"\"Shows the phenotypes ranked by (indicated) composition in the population of patients entered \n",
    "    Parameters: patient_phen :  dictionary with patients as keys, with values being dictionaries with keys (\"pos\",\"neg\") \n",
    "                                 with a list of the positive and negative phenotypes presented by each patient\n",
    "    Returns: sorted_dict_bp: ordered dictionnary, with composition as sorting key and phenotypes as value\n",
    "    \"\"\"\n",
    "    best_phen={}\n",
    "    for pat in patient_phen:\n",
    "        for phen in patient_phen[pat][\"pos\"]:\n",
    "            if phen in best_phen:\n",
    "                best_phen[phen]+=1/len(patient_phen)\n",
    "            else:\n",
    "                best_phen[phen]=1/len(patient_phen)\n",
    "    sorted_dict_bp=collections.OrderedDict(sorted(best_phen.items(), key=operator.itemgetter(1), reverse=True))\n",
    "    return sorted_dict_bp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best phenotypes for patients with older paternal age\n",
    "get_best_phenotype_pat(old_pat_patient_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best phenotypes for patients with younger paternal age\n",
    "get_best_phenotype_pat(young_pat_patient_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show best phenotype for all patients having reported paternal age\n",
    "get_best_phenotype_pat(all_pat_patient_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mann Whitney U test for best phenotypes between yound and old paternal age\n",
    "mannwhitneyu([32,20,17,19,23,18,12],[37,27,32,27,14,19,22])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_old_pat=diagnostics.loc[old_pat_age][\"\\\\14_Disorders (in OMIM, from PhenoTips)\\\\\"]\n",
    "len(diag_old_pat.dropna())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natal_history_adult_diagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natal_history_adult_undiagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natal_history_pediatric_diagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natal_history_pediatric_undiagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diag_young_pat=diagnostics.loc[young_pat_age][\"\\\\14_Disorders (in OMIM, from PhenoTips)\\\\\"]\n",
    "len(diag_young_pat.dropna())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "135 diagnosed cases (56% of the 239) for 429 (41%) of all patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_data(filename,var_or_gene):\n",
    "    \"\"\"Retrieve genetic data from a text file (formatted from JSON file)\n",
    "    Parameters: filename: string, name of the text file with the genetic information\n",
    "                var_or_gene: string, \"Var\" if variants of \"Gen\" if genes\n",
    "    Returns: genomic_data: dictionary with UDN ID as key and list of dictionaries as value, each dictionary containing \n",
    "                           information about genes or variants\n",
    "    \"\"\"\n",
    "    genomic_data={}\n",
    "    with open(filename,\"r\") as pg:\n",
    "        lines=pg.readlines()\n",
    "        for line in lines:\n",
    "            if line.split(\"<\")[0]==\"ID\":\n",
    "                pid=line.split(\" \")[3].split(\"\\n\")[0]\n",
    "                genomic_data[pid]=[]\n",
    "            elif line.split(\"<\")[0]==var_or_gene:\n",
    "                var=int(line.split(\" \")[1].split(\"\\n\")[0])\n",
    "                genomic_data[pid].append({})\n",
    "            else:\n",
    "                if not(len(line.split(\" \"))==1):\n",
    "                    genomic_data[pid][var][line.split(\" \")[0].split(\"\\n\")[0]]=line.split(\" \")[1].split(\"\\n\")[0]\n",
    "    print(len(genomic_data))\n",
    "    for patient in genomic_data:\n",
    "        if not(patient in list(patient_phen.keys())):\n",
    "            genomic_data=removekey(genomic_data,patient)\n",
    "    print(len(genomic_data))\n",
    "    return genomic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants=get_gene_data(\"patient_genomic.txt\",\"Var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes=get_gene_data(\"patient_genes.txt\",\"Gene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of patients that present a candidate gene or candidate variants\n",
    "list_patient_genes=list(genes.keys())\n",
    "list_patient_variants=list(variants.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Patients in both\", len([patient for patient in patient_phen if patient in list_patient_genes and patient in list_patient_variants]))\n",
    "print(\"Patients with only genes\", len([patient for patient in patient_phen if patient in list_patient_genes and not(patient in list_patient_variants)]))\n",
    "print(\"Patients with only variants\", [patient for patient in patient_phen if not(patient in list_patient_genes) and patient in list_patient_variants])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of solved cases for people with an indicated gene or an indicated variant\n",
    "print(\"Number of solved and unsolved cases for genes indicated : \",collec.Counter(status.loc[list(genes.keys())][\"\\\\13_Status\\\\\"]))\n",
    "print(\"Number of solved and unsolved cases for variants indicated : \",collec.Counter(status.loc[list(variants.keys())][\"\\\\13_Status\\\\\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_genomic(genomic_data,var_or_gene):\n",
    "    \"\"\"Get the distribution associated to genomic data for its characteristics\n",
    "    Parameters: genomic_data: dictionary, with UDN ID as key and list with dictionaries as value, dict contaning characteristics\n",
    "                              of the considered genomic data\n",
    "                var_or_gene: string, \"Var\" if variants, \"Gen\" otherwise\n",
    "    Returns: gene_effects: counter, with distribution of characteristics for selected genomic data\n",
    "    \"\"\"\n",
    "    gene_list=[]\n",
    "    for patient in genomic_data:\n",
    "        for i in range(len(genomic_data[patient])):\n",
    "            if var_or_gene==\"Var\":\n",
    "                if \"effect\" in list(genomic_data[patient][i].keys()) and \"gene\" in list(genomic_data[patient][i].keys()):\n",
    "                    gene_list.append([genomic_data[patient][i][\"gene\"],genomic_data[patient][i][\"effect\"]])\n",
    "                else:\n",
    "                    gene_list.append([genomic_data[patient][i][\"gene\"],\"NA\"])\n",
    "            elif var_or_gene==\"Gen\":\n",
    "                if \"status\" in list(genomic_data[patient][i].keys()) and \"gene\" in list(genomic_data[patient][i].keys()):\n",
    "                    gene_list.append([genomic_data[patient][i][\"gene\"],genomic_data[patient][i][\"status\"]])\n",
    "                else:\n",
    "                    gene_list.append([genomic_data[patient][i][\"gene\"],\"NA\"])  \n",
    "            else:\n",
    "                print(\"var_or_gene must be Var or Gen\")\n",
    "    gene_effects=collec.Counter(np.array(gene_list)[:,1])\n",
    "    return gene_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the count of mutation types for candidate variants\n",
    "gene_effects=get_dist_genomic(variants,\"Var\")\n",
    "gene_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distribution of gene status for candidate genes\n",
    "gene_status=get_dist_genomic(genes,\"Gen\")\n",
    "gene_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_genomic_data(genomic_data,namefile,var_or_gene):\n",
    "    \"\"\"Show the distribution of counts of candidate genes or variant per patient in the UDN database\n",
    "    Parameters: genomic_data: dictionary, with UDN ID as key and list with dictionaries as value, dict contaning characteristics\n",
    "                              of the considered genomic data\n",
    "                namefile: string, file of the name to save the figure in \n",
    "                var_or_gene: string, \"variants\" if variants is considered, \"genes\" else\n",
    "    Returns: None\n",
    "    Show the distribution in a scatter plot and the counter, as well as total number of candidate genes/variants\n",
    "    \"\"\"\n",
    "    count_gene_per_patient=collec.Counter([len(genomic_data[patient]) for patient in genomic_data])\n",
    "    print(count_gene_per_patient)\n",
    "    X_gene=list(count_gene_per_patient)\n",
    "    Y_gene=[count_gene_per_patient[ct] for ct in X_gene]\n",
    "    print(\"Number of total candidate \",var_or_gene,\" : \",np.sum([X_gene[i]*Y_gene[i] for i in range(len(X_gene))]))\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(X_gene,Y_gene,\"o\")\n",
    "    plt.xticks(np.arange(0,18))\n",
    "    plt.title(\"Distribution of number of candidate \"+var_or_gene+\" per patient\")\n",
    "    plt.xlabel(\"Number of candidate \"+var_or_gene)\n",
    "    plt.ylabel(\"Count of patients\")\n",
    "    plt.savefig(namefile,bbox_inches=\"tight\",dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_genomic_data(variants,\"Count_dist_var_per_pat_2.png\",\"variants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_genomic_data(genes,\"Count_genes_per_pat_1.png\",\"genes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results are shown using the Mann Whitney U statistic. The closer to 0 the statistic, the more significantly different the distributions are -- this can also be assessed with the p value, if p<0.05 the distributions are significantly different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnosed vs undiagnosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age at UDN Evaluation, adult\")\n",
    "mannwhitneyu(np.array(demographics_adult_diagnosed[\"\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\\"]),np.array(demographics_adult_undiagnosed[\"\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age at UDN Evaluation, pediatric\")\n",
    "mannwhitneyu(np.array(demographics_pediatric_diagnosed[\"\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\\"]),np.array(demographics_pediatric_undiagnosed[\"\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age at symptom onset, adult\")\n",
    "mannwhitneyu(np.array(demographics_adult_diagnosed[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"]),np.array(demographics_adult_undiagnosed[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age at symptom onset, pediatric\")\n",
    "mannwhitneyu(np.array(demographics_pediatric_diagnosed[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"]),np.array(demographics_pediatric_undiagnosed[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Primary symptoms, adults\")\n",
    "print(np.median(np.multiply(list(pscount_ad),1/len(list_diagnosed_phen)*100)),np.median(np.multiply(list(pscount_and),1/len(list_undiagnosed_phen)*100)))\n",
    "mannwhitneyu(np.multiply(list(pscount_ad),1/len(list_diagnosed_phen)*100),np.multiply(list(pscount_and),1/len(list_undiagnosed_phen)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Primary symptoms, pediatric\")\n",
    "print(np.median(np.multiply(list(pscount_pd),1/len(list_diagnosed_phen)*100)),np.median(np.multiply(list(pscount_pnd),1/len(list_undiagnosed_phen)*100)))\n",
    "mannwhitneyu(np.multiply(list(pscount_pd),1/len(list_diagnosed_phen)*100),np.multiply(list(pscount_pnd),1/len(list_undiagnosed_phen)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clinical sites, adults\")\n",
    "print(np.median(np.multiply(list(cscount_ad),1/len(list_diagnosed_phen)*100)),np.median(np.multiply(list(cscount_and),1/len(list_undiagnosed_phen)*100)))\n",
    "mannwhitneyu(np.multiply(list(cscount_ad),1/len(list_diagnosed_phen)*100),np.multiply(list(cscount_and),1/len(list_undiagnosed_phen)*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clinical sites, pediatric\")\n",
    "print(np.median(np.multiply(list(cscount_pd),1/len(list_diagnosed_phen)*100)),np.median(np.multiply(list(cscount_pnd),1/len(list_undiagnosed_phen)*100)))\n",
    "mannwhitneyu(np.multiply(list(cscount_pd),1/len(list_diagnosed_phen)*100),np.multiply(list(cscount_pnd),1/len(list_undiagnosed_phen)*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of unique phenotypes in the phenotype Dataframe\n",
    "mat_phen_ind=[]\n",
    "uniquep=[]\n",
    "for i,phen in enumerate(header_phen):\n",
    "    if not(phen.split(\"\\\\\")[-2] in uniquep):\n",
    "        mat_phen_ind.append(i)\n",
    "        uniquep.append(phen.split(\"\\\\\")[-2])\n",
    "len(mat_phen_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the patient ID column out of the phenotype dataframe\n",
    "matrix_phen=phenotypes.drop(\"Patient ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the phenotype dataframe to obtain a matrix of unique phenotypes, with only patients that have been evaluated,\n",
    "# with 1 if the phenotype is positively present, 0 if negative or NaN\n",
    "mat_phen=matrix_phen.iloc[:,mat_phen_ind]\n",
    "mat_phen=mat_phen.loc[list(patient_phen.keys())]\n",
    "mat_phen=mat_phen.replace(to_replace={\"Positive\": 1, \"Negative\": 0, np.nan: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the phenotype dataframe to obtain a matrix of unique phenotypes, with only patients that have been evaluated,\n",
    "# with 1 if the phenotype is positively present, 0 if negative or NaN\n",
    "mat_phen_adult=matrix_phen.iloc[:,mat_phen_ind]\n",
    "mat_phen_adult=mat_phen_adult.loc[adult_patients]\n",
    "mat_phen_adult=mat_phen_adult.replace(to_replace={\"Positive\": 1, \"Negative\": 0, np.nan: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the phenotype dataframe to obtain a matrix of unique phenotypes, with only patients that have been evaluated,\n",
    "# with 1 if the phenotype is positively present, 0 if negative or NaN\n",
    "mat_phen_pediatric=matrix_phen.iloc[:,mat_phen_ind]\n",
    "mat_phen_pediatric=mat_phen_pediatric.loc[pediatric_patients]\n",
    "mat_phen_pediatric=mat_phen_pediatric.replace(to_replace={\"Positive\": 1, \"Negative\": 0, np.nan: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matrix is comprised of 1042 patients with at least 1 phenotype, and 3965 unique phenotypes\n",
    "mat_phen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matrix is comprised of 232 patients with at least 1 phenotype, and 3965 unique phenotypes\n",
    "mat_phen_adult.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matrix is comprised of 809 patients with at least 1 phenotype, and 3965 unique phenotypes\n",
    "mat_phen_pediatric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute the jaccard similarity matrix for the phenotypic matrix, total patients\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "jac_sim_un = 1 - pairwise_distances(mat_phen, metric = \"jaccard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute the jaccard similarity matrix for the phenotypic matrix, adult patients\n",
    "jac_sim_un_adult = 1 - pairwise_distances(mat_phen_adult, metric = \"jaccard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute the jaccard similarity matrix for the phenotypic matrix, pediatric patients\n",
    "jac_sim_un_pediatric = 1 - pairwise_distances(mat_phen_pediatric, metric = \"jaccard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_of_patients_js(UDN_IDs,sim_matrix):\n",
    "    \"\"\"Constructs the graph of UDN patients using the similarity matrix computed: nodes are patients, edges between patient\n",
    "    i and j is proportional to the similarity between these two patients\n",
    "    Parameters: UDN_IDs: list of UDN IDs of patients to consider\n",
    "                sim_matrix: array, similarity matrix of pairwise similarity between each patient\n",
    "    Returns : G: networkx graph of UDN patients \n",
    "              pos: array, positions of nodes \n",
    "    \"\"\"\n",
    "    G= nx.Graph()\n",
    "    elist=[]\n",
    "    print(\"udnlen\",len(UDN_IDs))\n",
    "    print(\"cslen\",len(sim_matrix))\n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        G.add_node(UDN_IDs[i])\n",
    "        for j in range(i,sim_matrix.shape[1]):\n",
    "            elist.append((UDN_IDs[i],UDN_IDs[j],sim_matrix[i,j]))\n",
    "    G.add_weighted_edges_from(elist)\n",
    "    pos=nx.spring_layout(G,dim=2)\n",
    "    return G,pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_un,pos_un=graph_of_patients_js(list(patient_phen.keys()),jac_sim_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_un_adult,pos_un_adult=graph_of_patients_js(adult_patients,jac_sim_un_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_un_pediatric,pos_un_pediatric=graph_of_patients_js(pediatric_patients,jac_sim_un_pediatric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes the computed graph in a gml format, to be able to use Gephi to analyze it further\n",
    "nx.write_gml(graph_un,\"graph_un.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes the computed graph in a gml format, to be able to use Gephi to analyze it further\n",
    "nx.write_gml(graph_un_adult,\"graph_un_adult.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes the computed graph in a gml format, to be able to use Gephi to analyze it further\n",
    "nx.write_gml(graph_un_pediatric,\"graph_un_pediatric.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters_community(graph,resolution):\n",
    "    \"\"\"Compute the clusters in a graph using Louvain's community detection method\n",
    "    Parameters : graph: networkx graph of UDN patients computed using the pairwise similarity between patients\n",
    "    Returns: clusters: dictionary with the cluster number as key and a list containing all the patients in the cluster\n",
    "                       as value\n",
    "    \"\"\"\n",
    "    partition = community_louvain.best_partition(graph,resolution=resolution)\n",
    "    print(\"Partition done\")\n",
    "    clusters={}\n",
    "    for node in partition.keys():\n",
    "        if not(partition[node] in clusters.keys()):\n",
    "            clusters[partition[node]]=[node]\n",
    "        else:\n",
    "            clusters[partition[node]].append(node)\n",
    "    count=0\n",
    "    for cluster in clusters.keys():\n",
    "        print(\"Length of cluster \",cluster,\":\",len(clusters[cluster]))\n",
    "        if len(clusters[cluster])==1:\n",
    "            count+=1\n",
    "    print(\"Number of clusters with only one patient (outliers) :\",count)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_un=compute_clusters_community(graph_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_un_adult_test=compute_clusters_community(graph_un_adult,3.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_un_pediatric_test=compute_clusters_community(graph_un_pediatric,1.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute the indices of clusters with more than 2 patients, the indices of pairs and the indices of groups with only 1\n",
    "ind_groups=[cluster for cluster in clusters_un if len(clusters_un[cluster])>2]\n",
    "ind_pairs=[cluster for cluster in clusters_un if len(clusters_un[cluster])==2]\n",
    "ind_outliers=[cluster for cluster in clusters_un if len(clusters_un[cluster])==1]\n",
    "ind_groups,ind_pairs,ind_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute the indices for different types of groups: more than 2 or 3, only 2 or 3, more than 10...\n",
    "ind_lg_groups_adult=[cluster for cluster in clusters_un_adult if len(clusters_un_adult[cluster])>9]\n",
    "ind_sm_groups_adult=[cluster for cluster in clusters_un_adult if len(clusters_un_adult[cluster])<10 and len(clusters_un_adult[cluster])>2]\n",
    "ind_groups_pediatric=[cluster for cluster in clusters_un_pediatric if len(clusters_un_pediatric[cluster])>2]\n",
    "ind_pairs_adult=[cluster for cluster in clusters_un_adult if len(clusters_un_adult[cluster])==2]\n",
    "ind_pairs_pediatric=[cluster for cluster in clusters_un_pediatric if len(clusters_un_pediatric[cluster])==2]\n",
    "ind_groups_adult_test=[0,1,2,3]\n",
    "ind_other_adult_test=[4,13]\n",
    "ind_groups_pediatric_test=[0,1,2,3,4]\n",
    "ind_other_pediatric_test=[5,6,7,8,9,10,12]\n",
    "print(\"Lg groups adult network : \",ind_lg_groups_adult)\n",
    "print(\"Sm groups adult network : \",ind_sm_groups_adult)\n",
    "print(\"Pairs adult network : \",ind_pairs_adult)\n",
    "print(\"Clusters pediatric network : \",ind_groups_pediatric)\n",
    "print(\"Pairs pediatric network : \",ind_pairs_pediatric)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are phenotypes in common between pairs; prints the phenotype in common \n",
    "def pair_analysis(clusters_un,ind_pairs,patient_phen):\n",
    "    for cluster in ind_pairs:\n",
    "        print(\"Cluster C\",cluster)\n",
    "        if len(clusters_un[cluster])==2:\n",
    "            print(set(patient_phen[clusters_un[cluster][0]][\"pos\"]) & set(patient_phen[clusters_un[cluster][1]][\"pos\"]))\n",
    "        elif len(clusters_un[cluster])==3:\n",
    "            print(\"all : \",set(patient_phen[clusters_un[cluster][0]][\"pos\"]) & set(patient_phen[clusters_un[cluster][1]][\"pos\"]) & set(patient_phen[clusters_un[cluster][2]][\"pos\"]))\n",
    "            print(\"0 and 1 : \",set(patient_phen[clusters_un[cluster][0]][\"pos\"]) & set(patient_phen[clusters_un[cluster][1]][\"pos\"]))\n",
    "            print(\"1 and 2 : \",set(patient_phen[clusters_un[cluster][1]][\"pos\"]) & set(patient_phen[clusters_un[cluster][2]][\"pos\"]))\n",
    "            print(\"0 and 2 : \",set(patient_phen[clusters_un[cluster][0]][\"pos\"]) & set(patient_phen[clusters_un[cluster][2]][\"pos\"]))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Adult network\")\n",
    "pair_analysis(clusters_un_adult_test,ind_other_adult_test,patient_phen)\n",
    "print(\"---------------------\")\n",
    "print(\"Pediatric network\")\n",
    "pair_analysis(clusters_un_pediatric_test,ind_other_pediatric_test,patient_phen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nb of HPO terms for groups of 2 or 3 patients on avg\n",
    "all_HPO_counts_sm=[]\n",
    "print(\"Adult clusters\")\n",
    "for i in ind_other_adult_test:\n",
    "    all_HPO_counts_sm.append(np.average(HPO_count_adult_test[i]))\n",
    "    print(\"Cluster C\",i,\" : \",np.average(HPO_count_adult_test[i]))\n",
    "print(\"Pediatric clusters\")\n",
    "for i in ind_other_pediatric_test:\n",
    "    all_HPO_counts_sm.append(np.average(HPO_count_pediatric_test[i]))\n",
    "    print(\"Cluster C\",i,\" : \",np.average(HPO_count_pediatric_test[i]))\n",
    "print(\"Overall average : \",np.average(all_HPO_counts_sm),\" CI 95% : \",get_CI(all_HPO_counts_sm))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diag_OR(clusters,clusters_ind,status):\n",
    "    \"\"\"Calculate the Odds Ratio for the probability of being diagnosed linked to being in a certain cluster\n",
    "    Parameters: clusters: dictionary with cluster number as key and list of patients in cluster as value\n",
    "                clusters_ind: list, indices of cluster to take into account \n",
    "                status: string, status of the patient (if patient's case is solved or not)\n",
    "    Returns: OR_diag: dictionary with cluster number as key and the Odds Ratio (OR) for each cluster\n",
    "    \"\"\"\n",
    "    count_diag_clusters={cluster: 0 for cluster in clusters_ind}\n",
    "    for cluster in clusters_ind:\n",
    "        for patient in clusters[cluster]:\n",
    "            if status.loc[patient][\"\\\\13_Status\\\\\"]==\"solved\":\n",
    "                count_diag_clusters[cluster]+=1\n",
    "    OR_diag,IC={},{}\n",
    "    def IC_func(sign,OR,a,b,c,d):\n",
    "        if (a==0 or b==0 or c==0 or d==0):\n",
    "            return None\n",
    "        if sign==\"up\":\n",
    "            return np.exp(np.log(OR)+1.96*np.sqrt(1/a+1/b+1/c+1/d))\n",
    "        else:\n",
    "            return np.exp(np.log(OR)-1.96*np.sqrt(1/a+1/b+1/c+1/d))\n",
    "    for cluster in count_diag_clusters:\n",
    "        count_diag_notin=np.sum([count_diag_clusters[cl] for cl in clusters_ind if not(cl==cluster)])\n",
    "        OR_diag[cluster]=(count_diag_clusters[cluster]/count_diag_notin)/((len(clusters[cluster])-count_diag_clusters[cluster])/np.sum([len(clusters[cl])-count_diag_clusters[cl] for cl in clusters_ind]))\n",
    "        IC[cluster]={\"up\": IC_func(\"up\",OR_diag[cluster],count_diag_clusters[cluster],(len(clusters[cluster])-count_diag_clusters[cluster]),count_diag_notin,np.sum([len(clusters[cl])-count_diag_clusters[cl] for cl in clusters_ind]))\n",
    "                    ,\"low\": IC_func(\"low\",OR_diag[cluster],count_diag_clusters[cluster],(len(clusters[cluster])-count_diag_clusters[cluster]),count_diag_notin,np.sum([len(clusters[cl])-count_diag_clusters[cl] for cl in clusters_ind]))}\n",
    "    return OR_diag,IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_diag_lg_adult,IC_lg_adult=calculate_diag_OR(clusters_un_adult,ind_lg_groups_adult,status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_diag_sm_adult,IC_sm_adult=calculate_diag_OR(clusters_un_adult,ind_sm_groups_adult,status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_diag_pediatric,IC_pediatric=calculate_diag_OR(clusters_un_pediatric,ind_groups_pediatric,status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_diag_adult_test,IC_adult_test=calculate_diag_OR(clusters_un_adult_test,ind_groups_adult_test,status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_diag_pediatric_test,IC_pediatric_test=calculate_diag_OR(clusters_un_pediatric_test,ind_groups_pediatric_test,status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phenotype_enrichment_analysis(patients_clustered,patient_phen,polarity_HPO):\n",
    "    \"\"\"Get the phenotypes shared by the most patients in the cluster according to polarity (positive or negative)\n",
    "    Parameters: patients_clustered: list of patients in the cluster \n",
    "                patient_phen: dictionary of unique phenotypes associated with each patient; key is patient, value is dictionary\n",
    "                with key \"pos\" or \"neg\" and value list of unique phenotypes with positive or negative association\n",
    "                polarity_HPO: string, \"pos\" or \"neg\", polarity wanted for the phenotype enrichment analysis\n",
    "    Returns: phen_ranked: list of best phenotypes ranked according to their representation in the cluster\n",
    "             values: list of proportion of patients presenting the phenotype in the phen_ranked same position (ex: values[i]\n",
    "             will have the represention of phenotype phen_ranked[i])\n",
    "    \"\"\"\n",
    "    phen_count={}\n",
    "    for patient in patients_clustered:\n",
    "        for phen in patient_phen[patient][polarity_HPO]:\n",
    "            if not(phen in phen_count):\n",
    "                phen_count[phen]=1/len(patients_clustered)\n",
    "            else:\n",
    "                phen_count[phen]+=1/len(patients_clustered)\n",
    "    phen_ranked=np.array([phen for phen in phen_count.keys()])\n",
    "    values=np.array([phen_count[phen] for phen in phen_ranked])\n",
    "    indrank=np.argsort(values)[::-1]\n",
    "    phen_ranked=phen_ranked[indrank]\n",
    "    values=values[indrank]\n",
    "    return phen_ranked,values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HPO_count(patients_clustered,HPO_terms):\n",
    "    \"\"\"get the count of HPO terms for patients in the cluster, and the average\n",
    "    Parameters: patients_clustered: dictionary with cluster number as key and list of patients in the cluster as value\n",
    "                HPO_terms: dictionary with patient as key and count of HPO terms for the patient as value\n",
    "    Returns: HPO_cluster: dictionary with cluster number as key and list of HPO numbers for each patient in the cluster as value\n",
    "             avg_HPO_clusters: dictionary with cluster number as key and average number of HPO terms per patient as value\n",
    "    \"\"\"\n",
    "    HPO_cluster = {i: [] for i in patients_clustered.keys()}\n",
    "    for cluster in patients_clustered:\n",
    "        for patient in patients_clustered[cluster]:\n",
    "            HPO_cluster[cluster].append(HPO_terms[patient])\n",
    "    avg_HPO_clusters = {cluster: np.average(HPO_cluster[cluster]) for cluster in patients_clustered.keys()}\n",
    "    CI_HPO_clusters = {cluster: get_CI(HPO_cluster[cluster]) for cluster in patients_clustered.keys()}\n",
    "    return HPO_cluster,avg_HPO_clusters,CI_HPO_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "HPO_count_adult,avg_HPO_clusters_adult,CI_HPO_clusters_adult=get_HPO_count(clusters_un_adult,HPO_terms)\n",
    "HPO_count_pediatric,avg_HPO_clusters_pediatric,CI_HPO_clusters_pediatric=get_HPO_count(clusters_un_pediatric,HPO_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "HPO_count_adult_test,avg_HPO_clusters_adult_test,CI_HPO_clusters_adult_test=get_HPO_count(clusters_un_adult_test,HPO_terms)\n",
    "HPO_count_pediatric_test,avg_HPO_clusters_pediatric_test,CI_HPO_clusters_pediatric_test=get_HPO_count(clusters_un_pediatric_test,HPO_terms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ranked positively and negatively associated phenotyeps for patients in each cluster (phen_ranked_pos \n",
    "# and phen_ranked_neg) \n",
    "# phen_ranked_pos (or _neg) is a dictionary with cluster number as key, and two arrays as value, one with the label\n",
    "# of phenotypes ranked to their composition, another with the composition of said phenotype in the cluster\n",
    "def get_phen_ranked(clusters_un,ind_groups):\n",
    "    phen_ranked_pos,phen_ranked_neg={cluster: [] for cluster in ind_groups},{cluster: [] for cluster in ind_groups}\n",
    "    for cluster in ind_groups:\n",
    "        phen_ranked_pos[cluster]=phenotype_enrichment_analysis(clusters_un[cluster],patient_phen,\"pos\")\n",
    "        phen_ranked_neg[cluster]=phenotype_enrichment_analysis(clusters_un[cluster],patient_phen,\"neg\")\n",
    "    return phen_ranked_pos,phen_ranked_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phen_ranked_pos_lg_adult,phen_ranked_neg_lg_adult=get_phen_ranked(clusters_un_adult,ind_lg_groups_adult)\n",
    "phen_ranked_pos_sm_adult,phen_ranked_neg_sm_adult=get_phen_ranked(clusters_un_adult,ind_sm_groups_adult)\n",
    "phen_ranked_pos_pediatric,phen_ranked_neg_pediatric=get_phen_ranked(clusters_un_pediatric,ind_groups_pediatric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phen_ranked_pos_TEST_adult,phen_ranked_neg_TEST_adult=get_phen_ranked(clusters_un_adult_test,ind_groups_adult_test)\n",
    "phen_ranked_pos_TEST_pediatric,phen_ranked_neg_TEST_pediatric=get_phen_ranked(clusters_un_pediatric_test,ind_groups_pediatric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_best_phenotypes_clusters(phen_ranked,nb,clusters_un):\n",
    "    \"\"\"Shows the nb best ranked phenotypes for each cluster that has ranked phenotypes\n",
    "    Parameters: phen_ranked: dictionary with cluster number as key, two arrays as value, one with list of phenotypes \n",
    "                             ranked according to composition, second with composition of each phenotype\n",
    "                nb: int, number of best phenotypes to show\n",
    "    Returns: None\n",
    "    Shows the nb best phenotypes for each cluster with their composition\n",
    "    \"\"\"\n",
    "    for cluster in phen_ranked:\n",
    "        print(\"Cluster \",cluster)\n",
    "        print(\"Cluster len \",len(clusters_un[cluster]))\n",
    "        n=(nb if len(phen_ranked[cluster][0])>10 else len(phen_ranked[cluster][0]))\n",
    "        for i in range(n):\n",
    "            print(phen_ranked[cluster][0][i],phen_ranked[cluster][1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_best_phenotypes_clusters(phen_ranked_pos_TEST_adult,5,clusters_un_adult_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_phen(clusters_un,phen_ranked,ind_groups,ad_or_ped,nb_phen,figsize,vmin,vmax,figname):\n",
    "    \"\"\"Displays heatmap of phenotype enrichment analysis for each cluster with analyzed composition\n",
    "    Parameters: clusters_un: dictionary with cluster number as key and list of patients in the cluster as value\n",
    "                phen_ranked: dictionary with cluster number as key, two arrays as value, one with list of phenotypes \n",
    "                             ranked according to composition, second with composition of each phenotype\n",
    "                ind_groups: list of int, indices to take into consideration\n",
    "                ad_or_ped: str, \"adult\" or \"pediatric\", changes the display\n",
    "                nb_phen: int, number of best phen to display\n",
    "                figsize: int, size of the figure displayed\n",
    "                vmin: int, minimum value for the heatmap (here percentage)\n",
    "                vmax: int, max value for the heatmap (here percentage)\n",
    "                figname: str, name under which you save the heatmap\n",
    "    Returns: None\n",
    "    Shows the heatmap of phenotype enrichment analysis for each cluster\n",
    "    \"\"\"\n",
    "    if ad_or_ped==\"adult\":\n",
    "        cluster_list=[\"Cluster C\"+str(cluster+1)+\"A, N=\"+str(len(clusters_un[cluster])) for cluster in ind_groups]\n",
    "    elif ad_or_ped==\"pediatric\":\n",
    "        cluster_list=[\"Cluster C\"+str(cluster+1)+\"P, N=\"+str(len(clusters_un[cluster])) for cluster in ind_groups]\n",
    "    list_phen_max=[]\n",
    "    for cluster in ind_groups:\n",
    "        i,j=0,0\n",
    "        while j<nb_phen:\n",
    "            if not(phen_ranked[cluster][0][i]) in list_phen_max:\n",
    "                list_phen_max.append(phen_ranked[cluster][0][i])\n",
    "                j+=1\n",
    "            i+=1\n",
    "    heatmap_mat=[[] for i in range(len(list_phen_max))]\n",
    "    for i,phen in enumerate(list_phen_max):\n",
    "        for cluster in ind_groups:\n",
    "            if phen in phen_ranked[cluster][0]:\n",
    "                indphen=np.where(phen_ranked[cluster][0]==phen)[0][0]\n",
    "                heatmap_mat[i].append(phen_ranked[cluster][1][indphen]*100)\n",
    "            else:\n",
    "                heatmap_mat[i].append(0)\n",
    "    sns.set()\n",
    "    fig,ax=plt.subplots(figsize=(figsize,figsize))\n",
    "    sns.heatmap(heatmap_mat,cbar=True,cmap=\"YlGnBu\",xticklabels=cluster_list,yticklabels=list_phen_max,ax=ax,vmin=vmin,vmax=vmax)\n",
    "    plt.ylabel(\"Phenotypes\")\n",
    "    plt.savefig(figname+\".png\",bbox_inches=\"tight\",dpi=350)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap for positive associations, adult\n",
    "heatmap_phen(clusters_un_adult_test,phen_ranked_pos_TEST_adult,ind_groups_adult_test,\"adult\",5,12,0,50,\"heatmap_adult_clusters_test_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap for positive associations, pediatric\n",
    "heatmap_phen(clusters_un_pediatric_test,phen_ranked_pos_TEST_pediatric,ind_groups_pediatric_test,\"pediatric\",5,12,0,75,\"heatmap_pediatric_clusters_test_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_collection(patients_clustered,metadata):\n",
    "    \"\"\"Get the metadata for each cluster \n",
    "    Parameters: patients_clustered: dictionary with cluster number as key and list of patients in the cluster as value\n",
    "                metadata: dataframe with metadata\n",
    "    Returns: metadata_clusters: dictionary with clusters as keys and dictionary as value, with key the metadata considered\n",
    "                                and list of values for patients in the cluster as value\n",
    "    \"\"\"\n",
    "    metadata_clusters={cl: {meta: [] for meta in list(metadata.columns)} for cl in patients_clustered.keys()}\n",
    "    for cl in patients_clustered:\n",
    "        for patient in patients_clustered[cl]:\n",
    "            for meta in list(metadata.columns)[1:]:\n",
    "                metadata_clusters[cl][meta].append(metadata.loc[patient][meta])\n",
    "    return metadata_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the demographics for the patient in the cluster \n",
    "demographics_coll_adult=metadata_collection(clusters_un_adult,demographics)\n",
    "demographics_coll_pediatric=metadata_collection(clusters_un_pediatric,demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics_coll_adult_test=metadata_collection(clusters_un_adult_test,demographics)\n",
    "demographics_coll_pediatric_test=metadata_collection(clusters_un_pediatric_test,demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the average and 95% CI for age at UDN evaluation\n",
    "def show_metadata_clusters(ind_groups,demographics_coll,attribute):\n",
    "    \"\"\"Shows the average and 95% CI for a certain attribute\n",
    "    Parameters: ind_groups: list of int, indices of clusters to consider\n",
    "                demographics_coll: dictionary with clusters as keys and dictionary as value, with key the metadata considered\n",
    "                                and list of values for patients in the cluster as value\n",
    "                attribute: str, attribute to consider (must be in demographics_coll)\n",
    "    Returns: None\n",
    "    Shows the avg and 95% CI\n",
    "    \"\"\"\n",
    "    for cluster in ind_groups:\n",
    "        lst=np.array(demographics_coll[cluster][attribute])\n",
    "        lst=lst[np.logical_not(np.isnan(lst))]\n",
    "        print(\"Cluster C\",cluster,\"Average \",attribute,\" : \",np.average(lst),\" CI 95% : \",get_CI(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metadata_clusters(ind_groups,demographics_coll,attribute):\n",
    "    \"\"\"Returns the average and 95% CI for an attribute\n",
    "    Parameters: ind_groups: list of int, indices of clusters to consider\n",
    "                demographics_coll: dictionary with clusters as keys and dictionary as value, with key the metadata considered\n",
    "                                and list of values for patients in the cluster as value\n",
    "                attribute: str, attribute to consider (must be in demographics_coll)\n",
    "    Returns: avg_att: dictionnary with clusters as keys and average of considered attribute as value\n",
    "             CI_att: dictionnary with clusters as keys and tuple with lower and upper CI 95% as value\"\"\"\n",
    "    avg_att,CI_att={cl: 0 for cl in ind_groups},{cl: (0,0) for cl in ind_groups}\n",
    "    for cluster in ind_groups:\n",
    "        lst=np.array(demographics_coll[cluster][attribute])\n",
    "        lst=lst[np.logical_not(np.isnan(lst))]\n",
    "        avg_att[cluster]=np.average(lst)\n",
    "        CI_att[cluster]=get_CI(lst)\n",
    "    return avg_att,CI_att"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_onset_adult,CI_onset_adult=get_metadata_clusters(ind_groups_adult,demographics_coll_adult,'\\\\00_Demographics\\\\Age at symptom onset in years\\\\')\n",
    "avg_UDN_eval_adult,CI_UDN_eval_adult=get_metadata_clusters(ind_groups_adult,demographics_coll_adult,'\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_onset_adult_test,CI_onset_adult_test=get_metadata_clusters(ind_groups_adult_test,demographics_coll_adult_test,'\\\\00_Demographics\\\\Age at symptom onset in years\\\\')\n",
    "avg_UDN_eval_adult_test,CI_UDN_eval_adult_test=get_metadata_clusters(ind_groups_adult_test,demographics_coll_adult_test,'\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_onset_pediatric,CI_onset_pediatric=get_metadata_clusters(ind_groups_pediatric,demographics_coll_pediatric,'\\\\00_Demographics\\\\Age at symptom onset in years\\\\')\n",
    "avg_UDN_eval_pediatric,CI_UDN_eval_pediatric=get_metadata_clusters(ind_groups_pediatric,demographics_coll_pediatric,'\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_onset_pediatric_test,CI_onset_pediatric_test=get_metadata_clusters(ind_groups_pediatric_test,demographics_coll_pediatric_test,'\\\\00_Demographics\\\\Age at symptom onset in years\\\\')\n",
    "avg_UDN_eval_pediatric_test,CI_UDN_eval_pediatric_test=get_metadata_clusters(ind_groups_pediatric_test,demographics_coll_pediatric_test,'\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_metadata_clusters(ind_groups_pediatric,demographics_coll_pediatric,'\\\\00_Demographics\\\\Age at symptom onset in years\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distrib(attribute,demographics_coll):\n",
    "    \"\"\"Get a distribution for an attribute\n",
    "    Parameters: attribute: string, attribute we want the distribution of\n",
    "    Returns: counter of the collection library (distribution)\n",
    "    \"\"\"\n",
    "    counter={}\n",
    "    for cluster in demographics_coll:\n",
    "        dc=np.array(demographics_coll[cluster][attribute])\n",
    "        if type(dc[0])==np.float64:\n",
    "            dc=dc[np.logical_not(np.isnan(dc))]\n",
    "        counter[cluster]=dict(collec.Counter(dc))\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_distrib_adult=get_distrib('\\\\00_Demographics\\\\Gender\\\\',demographics_coll_adult)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_distrib_adult_test=get_distrib('\\\\00_Demographics\\\\Gender\\\\',demographics_coll_adult_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_distrib_pediatric=get_distrib('\\\\00_Demographics\\\\Gender\\\\',demographics_coll_pediatric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_distrib_pediatric_test=get_distrib('\\\\00_Demographics\\\\Gender\\\\',demographics_coll_pediatric_test)\n",
    "gender_distrib_pediatric_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Kruskal Wallis for the distribution of HPO count between clusters \\\\ adult\n",
    "kr_HPO_ad=kruskal(HPO_count_adult_test[0],HPO_count_adult_test[1],HPO_count_adult_test[2],HPO_count_adult_test[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Kruskal Wallis for the distribution of HPO count between clusters \\\\ pediatric\n",
    "kr_HPO_ped=kruskal(HPO_count_pediatric_test[0],HPO_count_pediatric_test[1],HPO_count_pediatric_test[2],HPO_count_pediatric_test[3],HPO_count_pediatric_test[4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_value(value_considered,ad_or_ped,ind_clusters,demographics_coll):\n",
    "    \"\"\"get the Kruskal Wallis U index and p-value for a type of demographics\n",
    "    Parameters: value_considered: string, type of demographics we want the KW U index and p-value\n",
    "                ad_or_ped: str, \"adult\" or \"pediatric\", to consider one or the other cluster\n",
    "                ind_clusters: list of int, indices of clusters to consider\n",
    "                demographics_coll: dictionary with clusters as keys and dictionary as value, with key the metadata considered\n",
    "                                and list of values for patients in the cluster as value\n",
    "    Returns: Kruskal-Wallis statistic, 2-D tuple with H-index (0) and p-value (1)\n",
    "    Prints the KW H index and p-value\n",
    "    \"\"\"\n",
    "    dc={i: [] for i in ind_clusters}\n",
    "    for i in ind_clusters:\n",
    "        dc[i]=np.array(demographics_coll[i][value_considered])\n",
    "        if type(dc[i][0])==np.float64:\n",
    "            dc[i]=dc[i][np.logical_not(np.isnan(dc[i]))]\n",
    "    if ad_or_ped==\"adult\":\n",
    "        print(kruskal(dc[0],dc[1],dc[2],dc[3]))\n",
    "        return kruskal(dc[0],dc[1],dc[2],dc[3])\n",
    "    elif ad_or_ped==\"pediatric\":\n",
    "        print(kruskal(dc[0],dc[1],dc[2],dc[3],dc[4]))\n",
    "        return kruskal(dc[0],dc[1],dc[2],dc[3],dc[4])\n",
    "    else:\n",
    "        print(\"ad_or_ped can only be adult or pediatric\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KW test for Age at UDN evaluation // adult\n",
    "kr_UDN_ad=get_stats_value('\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\',\"adult\",ind_groups_adult_test,demographics_coll_adult_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KW test for Age at UDN evaluation // pediatric\n",
    "kr_UDN_ped=get_stats_value('\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\',\"pediatric\",ind_groups_pediatric_test,demographics_coll_pediatric_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KW test for Age at symptom onset // adult\n",
    "kr_onset_ad=get_stats_value('\\\\00_Demographics\\\\Age at symptom onset in years\\\\',\"adult\",ind_groups_adult_test,demographics_coll_adult_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KW test for Age at symptom onset // pediatric\n",
    "kr_onset_ped=get_stats_value('\\\\00_Demographics\\\\Age at symptom onset in years\\\\',\"pediatric\",ind_groups_pediatric_test,demographics_coll_pediatric_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from docx import Document\n",
    "from docx.shared import Inches\n",
    "n_ped,n_ad=5,4\n",
    "\n",
    "def create_table(n_ad,a_or_p,clusters_un,avg_HPO_clusters,CI_HPO_clusters,gender_distrib,OR_diag,IC_OR,avg_onset,CI_onset,avg_UDN_eval,CI_UDN_eval,docname):\n",
    "    \"\"\"Creates a word document with automatically rendered table of cluster characteristics\n",
    "    Parameters: n_ad: number of clusters \n",
    "                a_or_p: str, \"A\" or \"P\", changes the display \n",
    "                clusters_un: dictionnary with cluster as key and list of UDN IDs as value\n",
    "                avg_HPO_clusters: dictionnary with cluster as key and avg HPO per patient as value\n",
    "                CI_HPO_clusters: dictionnary with cluster as key and tuple of 95% CI for avg HPO as value\n",
    "                gender_distrib: dictionnary with cluster as key and count of female/male as value\n",
    "                OR_diag: dictionnary with cluster as key and OR as value\n",
    "                IC_OR: dictionnary with cluster as key and tuple of 95% CI for OR as value\n",
    "                avg_onset: dictionnary with cluster as key and avg onset as value\n",
    "                CI_onset: dictionnary with cluster as key and tuple of 95% CI for onset as value\n",
    "                avg_UDN_eval: dictionnary with cluster as key and avg UDN eval as value\n",
    "                CI_UDN_eval: dictionnary with cluster as key and tuple of 95% CI for avg UDN eval as value\n",
    "                docname: str, name of document to save\n",
    "    Returns: None\n",
    "    Saves a word document with table of cluster characteristics\n",
    "                \n",
    "    \"\"\"\n",
    "    document = Document()\n",
    "\n",
    "    document.add_heading('Tables'+docname, 0)\n",
    "\n",
    "    table = document.add_table(rows=1, cols=n_ad+1)\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = 'Clusters'\n",
    "    for i in range(1,n_ad+1):\n",
    "        hdr_cells[i].text = \"Cluster C\"+str(i)+a_or_p\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = \"# of patients per cluster\"\n",
    "    for i in range(1,n_ad+1):\n",
    "        row_cells[i].text = str(len(clusters_un[i-1]))\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = \"Female:male ratio\"\n",
    "    for i in range(1,n_ad+1):\n",
    "        row_cells[i].text = str(int(np.round_(gender_distrib[i-1][\"Female\"]*10/gender_distrib[i-1][\"Male\"])))+\":10\"\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = \"Avg # of HPO terms per patient\"\n",
    "    for i in range(1,n_ad+1):\n",
    "        row_cells[i].text = str(np.round_(avg_HPO_clusters[i-1],decimals=1))+\" (95% CI: \"+str(np.round_(CI_HPO_clusters[i-1][0],decimals=1))+\" - \"+str(np.round_(CI_HPO_clusters[i-1][1],decimals=1))+\")\"\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = \"Odds ratio diagnosed\"\n",
    "    for i in range(1,n_ad+1):\n",
    "        row_cells[i].text = str(np.round_(OR_diag[i-1],decimals=1))+\" (95% CI: \"+str(np.round_(IC_OR[i-1][\"low\"],decimals=1))+\" - \"+str(np.round_(IC_OR[i-1][\"up\"],decimals=1))+\")\"\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = \"Average age at onset in y\"\n",
    "    for i in range(1,n_ad+1):\n",
    "        row_cells[i].text = str(np.round_(avg_onset[i-1],decimals=1))+\" (95% CI: \"+str(np.round_(CI_onset[i-1][0],decimals=1))+\" - \"+str(np.round_(CI_onset[i-1][1],decimals=1))+\")\"\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = \"Average age at UDN evaluation in y\"\n",
    "    for i in range(1,n_ad+1):\n",
    "        row_cells[i].text = str(np.round_(avg_UDN_eval[i-1],decimals=1))+\" (95% CI: \"+str(np.round_(CI_UDN_eval[i-1][0],decimals=1))+\" - \"+str(np.round_(CI_UDN_eval[i-1][1],decimals=1))+\")\"\n",
    "    document.add_page_break()\n",
    "\n",
    "    document.save(docname+'.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(4,\"A\",clusters_un_adult_test,avg_HPO_clusters_adult_test,CI_HPO_clusters_adult_test,gender_distrib_adult_test,OR_diag_adult_test,IC_adult_test,avg_onset_adult_test,CI_onset_adult_test,avg_UDN_eval_adult_test,CI_UDN_eval_adult_test,\"adult_table_test_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(5,\"P\",clusters_un_pediatric_test,avg_HPO_clusters_pediatric_test,CI_HPO_clusters_pediatric_test,gender_distrib_pediatric_test,OR_diag_pediatric_test,IC_pediatric_test,avg_onset_pediatric_test,CI_onset_pediatric_test,avg_UDN_eval_pediatric_test,CI_UDN_eval_pediatric_test,\"pediatric_table_test_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_table(10,\"P\",clusters_un_pediatric,avg_HPO_clusters_pediatric,CI_HPO_clusters_pediatric,gender_distrib_pediatric,OR_diag_pediatric,IC_pediatric,avg_onset_pediatric,CI_onset_pediatric,avg_UDN_eval_pediatric,CI_UDN_eval_pediatric,\"pediatric_table\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_stat_table(kr_HPO_ad,kr_HPO_ped,kr_UDN_ad,kr_UDN_ped,kr_onset_ad,kr_onset_ped,docname):\n",
    "    \"\"\"Creates word document to save Kruskal Wallis results for clusters\n",
    "    Parameters: kr_HPO_ad: Kruskal Wallis results of HPO for adult clusters\n",
    "                kr_HPO_ped: Kruskal Wallis results of HPO for pediatric clusters\n",
    "                kr_UDN_ad: Kruskal Wallis results of UDN eval for adult clusters\n",
    "                kr_UDN_ped: Kruskal Wallis results of UDN eval for pediatric clusters\n",
    "                kr_onset_ad: Kruskal Wallis results of onset age for adult clusters\n",
    "                kr_onset_ped: Kruskal Wallis results of onset age for pediatric clusters\n",
    "                docname: str, name of doc to save\n",
    "    Returns: None\n",
    "    Saves the word document with docname\n",
    "    \"\"\"\n",
    "    document = Document()\n",
    "\n",
    "    document.add_heading('Tables stats '+docname, 0)\n",
    "\n",
    "    table = document.add_table(rows=1, cols=3)\n",
    "    hdr_cells = table.rows[0].cells\n",
    "    hdr_cells[0].text = 'Variable'\n",
    "    hdr_cells[1].text = 'Kruskal-Wallis H index and p-value'\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[1].text = \"Adult\"\n",
    "    row_cells[2].text = \"Pediatric\"\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = \"Avg # of HPO terms per patient\"\n",
    "    row_cells[1].text = \"H = \"+str(np.round_(kr_HPO_ad[0],decimals=1))+\" , p = \"+str(np.format_float_scientific(kr_HPO_ad[1],precision=2))\n",
    "    row_cells[2].text = \"H = \"+str(np.round_(kr_HPO_ped[0],decimals=1))+\" , p = \"+str(np.format_float_scientific(kr_HPO_ped[1],precision=2))\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = \"Average age at onset in y\"\n",
    "    row_cells[1].text = \"H = \"+str(np.round_(kr_onset_ad[0],decimals=1))+\" , p = \"+str(np.format_float_scientific(kr_onset_ad[1],precision=2))\n",
    "    row_cells[2].text = \"H = \"+str(np.round_(kr_onset_ped[0],decimals=1))+\" , p = \"+str(np.format_float_scientific(kr_onset_ped[1],precision=2))\n",
    "    row_cells = table.add_row().cells\n",
    "    row_cells[0].text = \"Average age at UDN evaluation in y\"\n",
    "    row_cells[1].text = \"H = \"+str(np.round_(kr_UDN_ad[0],decimals=1))+\" , p = \"+str(np.format_float_scientific(kr_UDN_ad[1],precision=2))\n",
    "    row_cells[2].text = \"H = \"+str(np.round_(kr_UDN_ped[0],decimals=1))+\" , p = \"+str(np.format_float_scientific(kr_UDN_ped[1],precision=2))\n",
    "    document.add_page_break()\n",
    "\n",
    "    document.save(docname+'.docx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_stat_table(kr_HPO_ad,kr_HPO_ped,kr_UDN_ad,kr_UDN_ped,kr_onset_ad,kr_HPO_ped,\"statistics adult and pediatric_3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Get HPO numbers for phenotypes in database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# returns the HPO mapping, with HPO terms as value, and dictionnary as value with keys : id (the HPO id), parent \n",
    "# (list with parents of the HPO term); syn (HPO term synonym if applicable), xref (external references numbers, for UMLS, etc.)\n",
    "mapping_HPO={}\n",
    "with open(\"hpo.txt\",\"r+\") as hpo:\n",
    "    lines = hpo.readlines()\n",
    "    i=0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].split(\":\")[0]==\"id\":\n",
    "            hpoid=lines[i].split(\" \")[1].split(\"\\n\")[0]\n",
    "            name=\"\"\n",
    "            for namestr in lines[i+1].split(\" \")[1:]:\n",
    "                name+=namestr+\" \"\n",
    "            name=name.split(\"\\n\")[0]\n",
    "            mapping_HPO[name]={\"id\": hpoid, \"xref\": [], \"parent\": [], \"syn\":[]}\n",
    "        if lines[i].split(\" \")[0]==\"xref:\":\n",
    "            mapping_HPO[name][\"xref\"].append(lines[i].split(\" \")[1].split(\"\\n\")[0])\n",
    "        if lines[i].split(\" \")[0]==\"is_a:\":\n",
    "            mapping_HPO[name][\"parent\"].append(lines[i].split(\" \")[1])\n",
    "        if lines[i].split(\" \")[0]==\"synonym:\":\n",
    "            namesyn=\"\"\n",
    "            for namestr in lines[i].split(\" \")[1:]:\n",
    "                namesyn+=namestr+\" \"\n",
    "            namesyn=namesyn.split(\"\\\"\")[1].split(\"'\")[0]\n",
    "            if len(namesyn.split(\"obsolete \"))>1:\n",
    "                namesyn=namesyn.split(\"obsolete \")[1]\n",
    "            mapping_HPO[name][\"syn\"].append(namesyn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# additionnal manual mapping (for mistakes/missing tokens/missing terms...)\n",
    "syn_mapping={}\n",
    "for dis in mapping_HPO:\n",
    "    for syn in mapping_HPO[dis][\"syn\"]:\n",
    "        syn_mapping[syn]=mapping_HPO[dis][\"id\"]\n",
    "syn_mapping[\"Contracture of the distal interphalangeal joints of the fingers\"]=\"HP:0009697\"\n",
    "syn_mapping[\"Decreased testosterone in males\"]=\"HP:0040171\"\n",
    "syn_mapping[\"EMG myopathic abnormalities\"]=\"HP:0003458\"\n",
    "syn_mapping[\"EMG myotonic discharges\"]=\"HP:0100284\"\n",
    "syn_mapping[\"Increased IgE level\"]=\"HP:0003212\"\n",
    "syn_mapping[\"EMG chronic denervation signs\"]=\"HP:0003444\"\n",
    "syn_mapping[\"Primitive reflexes (palmomental, snout, glabellar)\"]=\"HP:0002476\"\n",
    "syn_mapping[\"EMG slow motor conduction\"]=\"HP:0100287\"\n",
    "syn_mapping[\"Severe Myopia\"]=\"HP:0011003\"\n",
    "syn_mapping[\"Arthralgiaarthritis\"]=\"HP:0005059\"\n",
    "syn_mapping[\"Decreased CSF homovanillic acid (HVA)\"]=\"HP:0003785\"\n",
    "syn_mapping[\"Hip Subluxation\"]=\"HP:0030043\"\n",
    "syn_mapping[\"Increased IgM level\"]=\"HP:0003496\"\n",
    "syn_mapping[\"Hyperpigmentedhypopigmented macules\"]=\"HP:0007441\"\n",
    "syn_mapping[\"Noninflammatory macular atrophy\"]=\"HP:0007401\"\n",
    "syn_mapping[\"Capillary hemangiomas\"]=\"HP:0005306\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the lungs\"]=\"HP:0006703\"\n",
    "syn_mapping[\"Abnormal serum cobalamin\"]=\"HP:0040126\"\n",
    "syn_mapping[\"Cone-rod dystrophy\"]=\"HP:0000548\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the inner ear\"]=\"HP:0008774\"\n",
    "syn_mapping[\"Decreased number of CD4+ T cells\"]=\"HP:0032183\"\n",
    "syn_mapping[\"Enlarged kidneys\"]=\"HP:0000113\"\n",
    "syn_mapping[\"Nephroblastoma (Wilms tumor)\"]=\"HP:0002667\"\n",
    "syn_mapping[\"Cervical vertebral fusion (C2C3)\"]=\"HP:0002949\"\n",
    "syn_mapping[\"Pulmonary hypertension\"]=\"HP:0030950\"\n",
    "syn_mapping[\"Prominent epicanthal folds\"]=\"HP:0000286\"\n",
    "syn_mapping[\"Cellulitis due to immunodeficiency\"]=\"HP:0100658\"\n",
    "syn_mapping[\"Abnormal brain cholinecreatine ratio by MRS\"]=\"HP:0012709\"\n",
    "syn_mapping[\"Small palpebral fissure\"]=\"HP:0045025\"\n",
    "syn_mapping[\"EMG impaired neuromuscular transmission\"]=\"HP:0100285\"\n",
    "syn_mapping[\"Absenthypoplastic coccyx\"]=\"HP:0008436\"\n",
    "syn_mapping[\"Short tubular bones (hand)\"]=\"HP:0001248\"\n",
    "syn_mapping[\"Increased serum Insulin-like growth factor 1\"]=\"HP:0030269\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the middle phalanx of the 4th toe\"]=\"HP:0100373\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the middle phalanx of the 5th toe\"]=\"HP:0100374\"\n",
    "syn_mapping[\"Cortical thickening (humeral)\"]=\"HP:0003868\"\n",
    "syn_mapping[\"Abnormality of Descemet's membrane\"]=\"HP:0011490\"\n",
    "syn_mapping[\"Increased serum free triiodothyronine (fT3)\"]=\"HP:0011788\"\n",
    "syn_mapping[\"Limited knee flexionextension\"]=\"HP:0005085\"\n",
    "syn_mapping[\"Limited pronationsupination of forearm\"]=\"HP:0006394\"\n",
    "syn_mapping[\"Biilateral vocal cord paralysis\"]=\"HP:0012820\"\n",
    "syn_mapping[\"Macroreticular retinal dystrophy\"]=\"HP:0000556\"\n",
    "syn_mapping[\"Congenital visual impairment\"]=\"HP:0000505\"\n",
    "syn_mapping[\"AtrophyDegeneration affecting the brainstem\"]=\"HP:0007366\"\n",
    "syn_mapping[\"Midface prominence\"]=\"HP:0430026\"\n",
    "syn_mapping[\"Basal lamina 'onion bulb' formation\"]=\"HP:0003400\"\n",
    "syn_mapping[\"Neutrophillia\"]=\"HP:0011897\"\n",
    "syn_mapping[\"Elevated circulating parathyroid hormone (PTH) level\"]=\"HP:0003165\"\n",
    "syn_mapping[\"Generalized cerebral atrophyhypoplasia\"]=\"HP:0007058\"\n",
    "syn_mapping[\"Somnolence\"]=\"HP:0001262\"\n",
    "syn_mapping[\"Increased IgA level\"]=\"HP:0003261\"\n",
    "syn_mapping[\"Increased blood urea nitrogen (BUN)\"]=\"HP:0003138\"\n",
    "syn_mapping[\"Decreased number of CD8+ T cells\"]=\"HP:0410385\"\n",
    "syn_mapping[\"Abnormality of acetylcarnitine metabolism\"]=\"HP:0012071\"\n",
    "syn_mapping[\"Hemisacrum (S2-S5)\"]=\"HP:0009790\"\n",
    "syn_mapping[\"EMG Positive sharp waves\"]=\"HP:0030007\"\n",
    "syn_mapping[\"Spastichyperactive bladder\"]=\"HP:0005340\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the clavicles\"]=\"HP:0006710\"\n",
    "syn_mapping[\"Congenital exotropia\"]=\"HP:0000577\"\n",
    "syn_mapping[\"Abnormal rapid eye movement (REM) sleep\"]=\"HP:0002494\"\n",
    "syn_mapping[\"Flared metaphyses (elbow)\"]=\"HP:0003950\"\n",
    "syn_mapping[\"Cortical subperiosteal resorption (humeral metaphyses)\"]=\"HP:0003909\"\n",
    "syn_mapping[\"Abnormality of ornithine metabolism\"]=\"HP:0012025\"\n",
    "syn_mapping[\"Oligodactyly (feet)\"]=\"HP:0001849\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the musculature of the pelvis\"]=\"HP:0001471\"\n",
    "syn_mapping[\"Status Asthmaticus\"]=\"HP:0012653\"\n",
    "syn_mapping[\"Vitreoretinal abnormalities\"]=\"HP:0007773\"\n",
    "syn_mapping[\"Abnormality of natural killer cell number\"]=\"HP:0040089\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the colon\"]=\"HP:0100811\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the nasal bone\"]=\"HP:0010940\"\n",
    "syn_mapping[\"Abnormality of B cell number\"]=\"HP:0010975\"\n",
    "syn_mapping[\"Abnormality of lymphocytes\"]=\"HP:0004332\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the eyebrow\"]=\"HP:0100840\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the mandible\"]=\"HP:0009118\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the distal phalanges of the hand\"]=\"HP:0009835\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the middle phalanges of the hand\"]=\"HP:0009843\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the thumb\"]=\"HP:0009601\"\n",
    "syn_mapping[\"Oligodactyly (hands)\"]=\"HP:0012165\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the middle phalanx of the 3rd toe\"]=\"HP:0100372\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the 3rd toe\"]=\"HP:0010331\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the 4th toe\"]=\"HP:0010337\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the 5th toe\"]=\"HP:0010343\"\n",
    "syn_mapping[\"AplasiaHypoplasia of toe\"]=\"HP:0001991\"\n",
    "syn_mapping[\"Abnormality of the metaphyses\"]=\"HP:0003907\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the ulna\"]=\"HP:0006495\"\n",
    "syn_mapping[\"Abnormality of the fibula\"]=\"HP:0010595\"\n",
    "syn_mapping[\"Abnormality of the metatarsal bones\"]=\"HP:0001832\"\n",
    "syn_mapping[\"Abnormality of the tibia\"]=\"HP:0002992\"\n",
    "syn_mapping[\"Decreasedabsent ankle reflexes\"]=\"HP:0200101\"\n",
    "syn_mapping[\"Abnormal enzymecoenzyme activity\"]=\"HP:0012379\"\n",
    "syn_mapping[\"Abnormality of carbohydrate metabolismhomeostasis\"]=\"HP:0011013\"\n",
    "syn_mapping[\"Abnormality of aspartate family amino acid metabolism\"]=\"HP:0010899\"\n",
    "syn_mapping[\"Abnormality of citrulline metabolism\"]=\"HP:0011965\"\n",
    "syn_mapping[\"Abnormality of homocysteine metabolism\"]=\"HP:0010919\"\n",
    "syn_mapping[\"Chromsome breakage\"]=\"HP:0040012\"\n",
    "syn_mapping[\"Decreased activity of the pyruvate dehydrogenase (PDH) complex\"]=\"HP:0002928\"\n",
    "syn_mapping[\"Abnormality of copper homeostasis\"]=\"HP:0010836\"\n",
    "syn_mapping[\"Abnormal serum iron\"]=\"HP:0040130\"\n",
    "syn_mapping[\"Abnormality of lipid metabolism\"]=\"HP:0003119\"\n",
    "syn_mapping[\"Abnormality of fatty-acid metabolism\"]=\"HP:0004359\"\n",
    "syn_mapping[\"Abnormality of carnitine metabolism\"]=\"HP:0010967\"\n",
    "syn_mapping[\"Abnormality of long-chain fatty-acid metabolism\"]=\"HP:0010964\"\n",
    "syn_mapping[\"Abnormality of glycine metabolism\"]=\"HP:0010895\"\n",
    "syn_mapping[\"Abnormality of the esophagus\"]=\"HP:0025270\"\n",
    "syn_mapping[\"Elevated hepatic transaminases\"]=\"HP:0002910\"\n",
    "syn_mapping[\"Abnormality of cardiac atrium\"]=\"HP:0005120\"\n",
    "syn_mapping[\"Ebstein's anomaly of the tricuspid valve\"]=\"HP:0010316\"\n",
    "syn_mapping[\"Effort-induced polymorphic ventricular tachycardias\"]=\"HP:0004758\"\n",
    "syn_mapping[\"Abnormality of circle of Willis\"]=\"HP:0012518\"\n",
    "syn_mapping[\"Coronary artery disease\"]=\"HP:0006704\"\n",
    "syn_mapping[\"Peripheral arterial disease\"]=\"HP:0004950\"\n",
    "syn_mapping[\"Dilatation of the ascending aorta\"]=\"\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the tragus\"]=\"HP:0009913\"\n",
    "syn_mapping[\"Adrenocorticotropin (ACTH) deficient adrenal insufficiency\"]=\"HP:0011735\"\n",
    "syn_mapping[\"Abnormality of the conjunctiva\"]=\"HP:0008054\"\n",
    "syn_mapping[\"Congenital primary aphakia\"]=\"\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the optic nerve\"]=\"HP:0008058\"\n",
    "syn_mapping[\"Abnormality of the vitreous humor\"]=\"HP:0004327\"\n",
    "syn_mapping[\"Congenital strabismus\"]=\"HP:0000486\"\n",
    "syn_mapping[\"Abnormality of vision evoked potentials\"]=\"HP:0000649\"\n",
    "syn_mapping[\"Hemianopic blurring of vision\"]=\"HP:0001125\"\n",
    "syn_mapping[\"Congenital glaucoma\"]=\"HP:0008007\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the testes\"]=\"HP:0010468\"\n",
    "syn_mapping[\"Aplastichypoplastic toenail\"]=\"HP:0010624\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the nails\"]=\"HP:0008386\"\n",
    "syn_mapping[\"EMG axonal abnormality\"]=\"HP:0003482\"\n",
    "syn_mapping[\"EMG neuropathic changes\"]=\"HP:0003445\"\n",
    "syn_mapping[\"Abnormality of the globus pallidus\"]=\"HP:0002454\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the corpus callosum\"]=\"HP:0007370\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the cerebral white matter\"]=\"HP:0012429\"\n",
    "syn_mapping[\"AtrophyDegeneration affecting the cerebrum\"]=\"HP:0007369\"\n",
    "syn_mapping[\"Porencephaly\"]=\"\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the cerebellar vermis\"]=\"HP:0006817\"\n",
    "syn_mapping[\"Brain very small\"]=\"\"\n",
    "syn_mapping[\"AtrophyDegeneration involving the spinal cord\"]=\"HP:0007344\"\n",
    "syn_mapping[\"AplasiaHypoplasia involving the central nervous system\"]=\"HP:0002977\"\n",
    "syn_mapping[\"AtrophyDegeneration affecting the central nervous system\"]=\"HP:0007367\"\n",
    "syn_mapping[\"CNS infection\"]=\"HP:0011450\"\n",
    "syn_mapping[\"Abnormal pyramidal signs\"]=\"HP:0007256\"\n",
    "syn_mapping[\"Hemiplegiahemiparesis\"]=\"HP:0004374\"\n",
    "syn_mapping[\"Reduced consciousnessconfusion\"]=\"HP:0004372\"\n",
    "syn_mapping[\"Inability to walk by childhoodadolescence\"]=\"HP:0006915\"\n",
    "syn_mapping[\"Abnormal emotionaffect behavior\"]=\"HP:0100851\"\n",
    "syn_mapping[\"Abnormal fearanxiety-related behavior\"]=\"HP:0100852\"\n",
    "syn_mapping[\"Abnormality of the lung\"]=\"HP:0002088\"\n",
    "syn_mapping[\"Abnormality of the tracheobronchial system\"]=\"\"\n",
    "syn_mapping[\"AplasiaHypoplasia of the ribs\"]=\"HP:0006712\"\n",
    "syn_mapping[\"Chronic recurrent multifocal osteomyelitis\"]=\"\"\n",
    "syn_mapping[\"Increased number of peripheral CD3+ T cells\"]=\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of unique HPO ID for unique phenotypes (HPO terms) in the network\n",
    "list_unique_phen,HPO_unique_phen=[],[]\n",
    "for phen in list(phenotypes)[1:]:\n",
    "    if not(phen.split(\"\\\\\")[-2] in list_unique_phen):\n",
    "        list_unique_phen.append(phen.split(\"\\\\\")[-2])\n",
    "for phen in list_unique_phen:\n",
    "    if phen in mapping_HPO:\n",
    "        HPO_unique_phen.append(mapping_HPO[phen][\"id\"])\n",
    "    else:\n",
    "        HPO_unique_phen.append(syn_mapping[phen])\n",
    "HPO_unique_phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"HPO_unique_phen.txt\",\"w\") as hpoun:\n",
    "    for i in range(len(HPO_unique_phen)):\n",
    "        hpoun.write(HPO_unique_phen[i]+\"\\n\")\n",
    "hpoun.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of unique HPO terms with more than 5% representation in pediatric clusters\n",
    "list_unique_phen_cl,HPO_unique_phen_cl=[],[]\n",
    "for cl in phen_ranked_pos_pediatric:\n",
    "    ind=[i for i in range(len(phen_ranked_pos_pediatric[cl][1])) if phen_ranked_pos_pediatric[cl][1][i]>0.05]\n",
    "    for j in ind:\n",
    "        list_unique_phen_cl.append(phen_ranked_pos_pediatric[cl][0][j])\n",
    "for phen in list_unique_phen_cl:\n",
    "    if phen in mapping_HPO:\n",
    "        HPO_unique_phen_cl.append(mapping_HPO[phen][\"id\"])\n",
    "    else:\n",
    "        HPO_unique_phen_cl.append(syn_mapping[phen])\n",
    "len(HPO_unique_phen_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saves a csv file with first column cluster number and second term HPO terms, for the 5 best phenotypes of clusters\n",
    "import csv\n",
    "with open('clusters_HPO_terms_adult.csv', mode='w') as clHPO:\n",
    "    csvwriter = csv.writer(clHPO, delimiter=',', quotechar='\"', quoting=csv.QUOTE_MINIMAL)\n",
    "    for cl in phen_ranked_pos_TEST_adult:\n",
    "        for j in range(5):\n",
    "            phen=phen_ranked_pos_TEST_adult[cl][0][j]\n",
    "            if phen in mapping_HPO:\n",
    "                csvwriter.writerow([cl, mapping_HPO[phen][\"id\"]])\n",
    "            else:\n",
    "                csvwriter.writerow([cl, syn_mapping[phen]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save all the unique HPO terms in a txt file\n",
    "with open(\"HPO_unique_phen_cl.txt\",\"w\") as hpoun:\n",
    "    for i in range(len(HPO_unique_phen_cl)):\n",
    "        hpoun.write(HPO_unique_phen_cl[i]+\"\\n\")\n",
    "hpoun.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
