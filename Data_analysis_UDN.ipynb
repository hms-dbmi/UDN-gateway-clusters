{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data analysis of UDN patients"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the UDN data resource using the HPDS Adapter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import ttest_ind\n",
    "import scipy.stats as st\n",
    "import scipy.sparse as sp\n",
    "import networkx as nx\n",
    "from community import community_louvain\n",
    "from scipy.stats import kruskal\n",
    "import seaborn as sns\n",
    "import collections as collec\n",
    "import os\n",
    "import xml.etree.ElementTree as ET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# matplotlib.pyplot settings for font size of figures\n",
    "font = {'size'   : 30}\n",
    "plt.rc('font', **font)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PicSureHpdsLib\n",
    "import PicSureClient\n",
    "# Connection to the PicSure Client w/ token: private token for people with authorized access\n",
    "connection = PicSureClient.Client.connect(\"https://udn.hms.harvard.edu/picsure\", token)\n",
    "adapter = PicSureHpdsLib.Adapter(connection)\n",
    "resource = adapter.useResource(\"8e8c7ed0-87ea-4342-b8da-f939e46bac26\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removekey(d, key):\n",
    "    \"\"\"This functions returns a copy of a dictionnary with a removed key\n",
    "    Parameters: d : dictionnary\n",
    "                key: the key that must be deleted\n",
    "    Returns: copy of dictionnary d without the key \n",
    "    \"\"\"\n",
    "    r = dict(d)\n",
    "    del r[key]\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_CI(a):\n",
    "    \"\"\"Returns the 95% confidence interval for a list/array a\n",
    "    Parameters: a: list or array we want the CI for\n",
    "    Returns: a tuple with 95% confidence interval\n",
    "    \"\"\"\n",
    "    return st.t.interval(0.95, len(a)-1, loc=np.mean(a), scale=st.sem(a,nan_policy='omit'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_df(column_head):\n",
    "    \"\"\"Enables the user to download the data as a pandas dataframe indexed by UDN IDs (through API)\n",
    "    Parameters : column_head : string, with the name of the header that will be selected. For example, if the columns that \n",
    "                                should be selected containt \"this string\", then column_head=\"this string\".\n",
    "    Returns: df : dataframe indexed by UDN IDs of the selected columns\n",
    "    \"\"\"\n",
    "    dictionary=resource.dictionary().find(column_head)\n",
    "    query=resource.query()\n",
    "    query.select().add(dictionary.keys())\n",
    "    query.select().add('\\\\000_UDN ID\\\\')\n",
    "    df=query.getResultsDataFrame()\n",
    "    df.set_index(\"\\\\000_UDN ID\\\\\", inplace=True)\n",
    "    query.select().clear()\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download phenotypic, status, genomic, primary symptoms and meta- data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes = get_data_df(\"\\\\04_Clinical symptoms and physical findings (in HPO, from PhenoTips)\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select only the phenotypes, and not the prenatal phenotypes\n",
    "columns_to_del=[]\n",
    "for col in list(phenotypes.columns)[1:]:\n",
    "    if \"Prenatal Phenotype\" in col.split('\\\\'):\n",
    "        columns_to_del.append(col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "phenotypes=phenotypes.drop(columns_to_del,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = get_data_df(\"\\\\13_Status\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes=get_data_df(\"\\\\11_Candidate genes\\\\\")\n",
    "variants=get_data_df(\"\\\\12_Candidate variants\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "primary_symptoms=get_data_df(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clinical_site=get_data_df('\\\\03_UDN Clinical Site\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "family_history=get_data_df(\"\\\\08_Family history (from PhenoTips)\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natal_history=get_data_df(\"\\\\09_Prenatal and perinatal history (from PhenoTips)\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demographics=get_data_df(\"\\\\00_Demographics\\\\\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diagnostics=get_data_df('\\\\14_Disorders (in OMIM, from PhenoTips)\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_patient_phenotypes(phenotypes):\n",
    "    \"\"\"Gets the list of unique phenotypes presented by the patients of the UDN \n",
    "    Parameters: phenotypes : pandas dataframe with the phenotypes\n",
    "    \n",
    "    Returns : patient_phen : dictionary with patients as keys, with values being dictionaries with keys (\"pos\",\"neg\") \n",
    "                             with a list of the positive and negative phenotypes presented by each patient\n",
    "    \"\"\"\n",
    "    header_phen=list(phenotypes)\n",
    "    patient_phen={patient: {\"pos\": [], \"neg\": []} for patient in phenotypes.index.values}\n",
    "    for patient,row in phenotypes.iterrows():\n",
    "        for i,phen in enumerate(row):\n",
    "            if phen==\"Positive\":\n",
    "                if not header_phen[i].split(\"\\\\\")[-2] in patient_phen[patient][\"pos\"]:\n",
    "                    patient_phen[patient][\"pos\"].append(header_phen[i].split(\"\\\\\")[-2])\n",
    "            elif phen==\"Negative\":\n",
    "                if not header_phen[i].split(\"\\\\\")[-2] in patient_phen[patient][\"neg\"]:\n",
    "                    patient_phen[patient][\"neg\"].append(header_phen[i].split(\"\\\\\")[-2])\n",
    "\n",
    "    for patient in patient_phen:\n",
    "        if len(patient_phen[patient][\"pos\"])==0 and len(patient_phen[patient][\"neg\"])==0:\n",
    "            patient_phen=removekey(patient_phen,patient)\n",
    "    return patient_phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_phen=get_patient_phenotypes(phenotypes)\n",
    "patient_phen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the counts of positivie, negative and total HPO terms\n",
    "HPO_terms_pos,HPO_terms_neg={patient: len(patient_phen[patient][\"pos\"]) for patient in patient_phen},{patient: len(patient_phen[patient][\"neg\"]) for patient in patient_phen}\n",
    "HPO_terms={patient: len(patient_phen[patient][\"pos\"])+len(patient_phen[patient][\"neg\"]) for patient in patient_phen}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of diagnosed and undiagnosed patients\n",
    "list_diagnosed=status.loc[status[\"\\\\13_Status\\\\\"] == \"solved\"].index.values.tolist()\n",
    "list_undiagnosed=status.loc[status[\"\\\\13_Status\\\\\"] != \"solved\"].index.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of diagnosed or undiagnosed patients that have at least one HPO term\n",
    "list_diagnosed_phen=[patient for patient in list_diagnosed if(patient in patient_phen)]\n",
    "list_undiagnosed_phen=[patient for patient in list_undiagnosed if(patient in patient_phen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframes with the phenotypes of diagnosed or undiagnosed patients that have at least one HPO term\n",
    "phenotypes_diagnosed=phenotypes.loc[list_diagnosed_phen]\n",
    "phenotypes_undiagnosed=phenotypes.loc[list_undiagnosed_phen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the HPO counts into a list of values \n",
    "HPO_list_pos=[HPO_terms_pos[patient] for patient in HPO_terms_pos]\n",
    "HPO_list_neg=[HPO_terms_neg[patient] for patient in HPO_terms_neg]\n",
    "HPO_list=[HPO_terms[patient] for patient in HPO_terms]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the total number of positive, negative, and all HPO terms in the database\n",
    "print(\"# of positive HPO : \",np.sum(HPO_list_pos),\"# of negative HPO : \",np.sum(HPO_list_neg),\"# of total HPO : \",np.sum(HPO_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of HPO terms # for diagnosed patients\n",
    "HPO_list_pos_d=[HPO_terms_pos[patient] for patient in list_diagnosed_phen]\n",
    "HPO_list_neg_d=[HPO_terms_neg[patient] for patient in list_diagnosed_phen]\n",
    "HPO_list_d=[HPO_terms[patient] for patient in list_diagnosed_phen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of HPO terms # for undiagnosed patients\n",
    "HPO_list_pos_nd=[HPO_terms_pos[patient] for patient in list_undiagnosed_phen]\n",
    "HPO_list_neg_nd=[HPO_terms_neg[patient] for patient in list_undiagnosed_phen]\n",
    "HPO_list_nd=[HPO_terms[patient] for patient in list_undiagnosed_phen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_stats_HPO_counts(HPO_list,HPO_list_pos,HPO_list_neg):\n",
    "    \"\"\"Show the average and confidence interval for HPO terms for a selected population\n",
    "    Parameters: HPO_list: list of HPO # for selected population\n",
    "                HPO_list_pos: list of positive HPO # for selected population\n",
    "                HPO_list_neg: list of negative HPO # for selected population\n",
    "    Returns: None\n",
    "    Shows the average and CI 95% for HPO counts\n",
    "    \"\"\"\n",
    "    print(\"HPO pos average : \",np.average(HPO_list_pos),\", CI 95% : \",get_CI(HPO_list_pos),\", HPO pos max : \",np.max(HPO_list_pos))\n",
    "    print(\"HPO neg average : \",np.average(HPO_list_neg),\", CI 95% : \",get_CI(HPO_list_neg),\", HPO neg max : \",np.max(HPO_list_neg))\n",
    "    print(\"HPO average : \",np.average(HPO_list),\", CI 95% : \",get_CI(HPO_list),\", HPO max : \",np.max(HPO_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats_HPO_counts(HPO_list,HPO_list_pos,HPO_list_neg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats_HPO_counts(HPO_list_d,HPO_list_pos_d,HPO_list_neg_d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_stats_HPO_counts(HPO_list_nd,HPO_list_pos_nd,HPO_list_neg_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_distrib_HPO(HPO_list,name):\n",
    "    \"\"\"Plots the distribution of count of HPO terms per patient\n",
    "    Parameters : HPO_list: list of counts for each patient of HPO terms\n",
    "                 name: string, title of the figure\n",
    "    Returns : None\n",
    "    Shows matplotlib plot of distribution of HPO\n",
    "    \"\"\"\n",
    "    distrib=collec.Counter(HPO_list)\n",
    "    X=[key for key in distrib.keys()]\n",
    "    Y=[distrib[key] for key in distrib.keys()]\n",
    "    plt.figure(figsize=(20,15))\n",
    "    plt.plot(X,Y,\"o\")\n",
    "    plt.xlabel(\"Number of HPO terms\")\n",
    "    plt.ylabel(\"Count of patients\")\n",
    "    plt.title(name)\n",
    "    plt.yscale(\"log\")\n",
    "    plt.xscale(\"log\")\n",
    "    plt.axes().set_ylim(None,200)\n",
    "    plt.show()\n",
    "    plt.savefig(\"HPO_terms_log\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_distrib_HPO(HPO_list,\"Distribution of HPO terms\")\n",
    "show_distrib_HPO(HPO_list_neg,\"Distribution of negative HPO terms\")\n",
    "show_distrib_HPO(HPO_list_pos,\"Distribution of positive HPO terms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### HPO large group stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of large groups in the HPO hierarchy\n",
    "large_groups_HPO=[]\n",
    "header_phen=list(phenotypes)[1:]\n",
    "for phen in header_phen:\n",
    "    if not(phen.split(\"\\\\\")[4] in large_groups_HPO):\n",
    "        large_groups_HPO.append(phen.split(\"\\\\\")[4])\n",
    "large_groups_HPO  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_large_groups_HPO_count(large_groups_HPO,phenotypes):\n",
    "    \"\"\"Returns the count of HPO terms that belong to a certain group of HPO terms\n",
    "    Parameters: large_groups : list of large groups that belong to the HPO hierarchy\n",
    "                phenotypes : pandas dataframe with the phenotypes\n",
    "    \n",
    "    Returns : group_count : dictionary with keys (\"pos\",\"neg\") that counts the occurrences of positive or negative HPO terms\n",
    "                            for each large group\n",
    "    \"\"\"\n",
    "    header_phen=list(phenotypes)\n",
    "    group_count={\"pos\":{lg: 0 for lg in large_groups_HPO},\"neg\": {lg: 0 for lg in large_groups_HPO}}\n",
    "    for patient,row in phenotypes.iterrows():\n",
    "        for i,phen in enumerate(row):\n",
    "            if phen==\"Positive\":\n",
    "                group_count[\"pos\"][header_phen[i].split(\"\\\\\")[4]]+=1\n",
    "            elif phen==\"Negative\":\n",
    "                group_count[\"neg\"][header_phen[i].split(\"\\\\\")[4]]+=1\n",
    "    return group_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "large_groups_HPO_count=get_large_groups_HPO_count(large_groups_HPO,phenotypes)\n",
    "large_groups_HPO_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the count of large groups for positive and negative terms of diagnosed patients\n",
    "large_groups_HPO_count_diagnosed=get_large_groups_HPO_count(large_groups_HPO,phenotypes_diagnosed)\n",
    "large_groups_HPO_count_diagnosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the count of large groups for positive and negative terms of undiagnosed patients\n",
    "large_groups_HPO_count_undiagnosed=get_large_groups_HPO_count(large_groups_HPO,phenotypes_undiagnosed)\n",
    "large_groups_HPO_count_undiagnosed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison HPO and Primary Symptoms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the association between unique phenotypes and the large groups they are related to in the HPO hierarchy\n",
    "# list_phenotypes_unique is a dictionary with the phenotypes as keys, and a list of associated large groups as value\n",
    "list_phenotypes_unique={}\n",
    "for phen in header_phen:\n",
    "    if not(phen.split(\"\\\\\")[-2] in list_phenotypes_unique):\n",
    "        list_phenotypes_unique[phen.split(\"\\\\\")[-2]]=[phen.split(\"\\\\\")[4]]\n",
    "    else:\n",
    "        if not(phen.split(\"\\\\\")[4] in list_phenotypes_unique[phen.split(\"\\\\\")[-2]]):\n",
    "            list_phenotypes_unique[phen.split(\"\\\\\")[-2]].append(phen.split(\"\\\\\")[4])\n",
    "list_phenotypes_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_link_between_PS_HPO(patient_phen,primary_symptoms,list_phenotypes_unique):\n",
    "    \"\"\"Returns the link count of occurrence of a certain HPO large group for patients with a certain primary symptom\n",
    "    Parameters : patient_phen: dictionary with the positive or negative unique HPO terms linked to patients \n",
    "                 primary_symptoms: dataframe with UDN IDs as index, and list of primary symptoms reported \n",
    "                 list_phenotypes_unique: dictionary of link between phenotypes and the large groups they are linked\n",
    "                 to in the HPO hierarchy\n",
    "    Returns : dictionary with keys (\"pos\",\"neg\") that contain a dictionary with the primary symptoms as keys and a dictionary \n",
    "              with the count for every large group of HPO hierarchy of occurrences as value\n",
    "    \"\"\"\n",
    "    link_PS_HPO={\"pos\": {}, \"neg\": {}}\n",
    "    for patient in patient_phen:\n",
    "        ps=list(primary_symptoms.loc[patient])[1]\n",
    "        if not(ps in link_PS_HPO[\"pos\"]):\n",
    "            link_PS_HPO[\"pos\"][ps]={}\n",
    "        if not(ps in link_PS_HPO[\"neg\"]):\n",
    "            link_PS_HPO[\"neg\"][ps]={}\n",
    "        for phen in patient_phen[patient][\"pos\"]:\n",
    "            for lg in list_phenotypes_unique[phen]:\n",
    "                if lg in link_PS_HPO[\"pos\"][ps]:\n",
    "                    link_PS_HPO[\"pos\"][ps][lg]+=1\n",
    "                else:\n",
    "                    link_PS_HPO[\"pos\"][ps][lg]=1\n",
    "        for phen in patient_phen[patient][\"neg\"]:\n",
    "            for lg in list_phenotypes_unique[phen]:\n",
    "                if lg in link_PS_HPO[\"neg\"][ps]:\n",
    "                    link_PS_HPO[\"neg\"][ps][lg]+=1\n",
    "                else:\n",
    "                    link_PS_HPO[\"neg\"][ps][lg]=1\n",
    "    return link_PS_HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the links between the primary symptoms and the HPO large groups\n",
    "link_PS_HPO=get_link_between_PS_HPO(patient_phen,primary_symptoms,list_phenotypes_unique)\n",
    "link_PS_HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show the ranked HPO groups for each primary symptom \n",
    "for ps in link_PS_HPO[\"pos\"]:\n",
    "    print(\"Primary symptom \",ps)\n",
    "    print(\"-------------------------------------------\")\n",
    "    if type(ps)==float:\n",
    "        continue\n",
    "    lg_list=list(link_PS_HPO[\"pos\"][ps])\n",
    "    val=[link_PS_HPO[\"pos\"][ps][lg] for lg in lg_list]\n",
    "    indsort=np.argsort(val)[::-1]\n",
    "    lg_list=np.array(lg_list)[indsort]\n",
    "    val=np.array(val)[indsort]\n",
    "    for i in range(len(indsort)):\n",
    "        print(lg_list[i],val[i])\n",
    "    print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of demographics and clinical site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the dataframes for patients with at least one phenotype, for diagnosed and undiagnosed \n",
    "demographics = demographics.loc[list(patient_phen)]\n",
    "demographics_diagnosed = demographics.loc[list_diagnosed_phen]\n",
    "demographics_undiagnosed = demographics.loc[list_undiagnosed_phen]\n",
    "clinical_site = clinical_site.loc[list(patient_phen)]\n",
    "clinical_site_diagnosed = clinical_site.loc[list_diagnosed_phen]\n",
    "clinical_site_undiagnosed = clinical_site.loc[list_undiagnosed_phen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of clinical sites for patients with at least one phenotype, for diagnosed and undiagnosed\n",
    "cscount = clinical_site.groupby('\\\\03_UDN Clinical Site\\\\')['Patient ID'].nunique()\n",
    "cscount_d = clinical_site_diagnosed.groupby('\\\\03_UDN Clinical Site\\\\')['Patient ID'].nunique()\n",
    "cscount_nd = clinical_site_undiagnosed.groupby('\\\\03_UDN Clinical Site\\\\')['Patient ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clinical site count general\")\n",
    "print(cscount)\n",
    "print(\"Clinical site count diagnosed\")\n",
    "print(cscount_d)\n",
    "print(\"Clinical site count undiagnosed\")\n",
    "print(cscount_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count race for general \",collec.Counter(demographics['\\\\00_Demographics\\\\Ethnicity\\\\']))\n",
    "print(\"Count race for diagnosed \",collec.Counter(demographics_diagnosed['\\\\00_Demographics\\\\Ethnicity\\\\']))\n",
    "print(\"Count race for undiagnosed \",collec.Counter(demographics_undiagnosed['\\\\00_Demographics\\\\Ethnicity\\\\']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Count race for general \",collec.Counter(demographics[\"\\\\00_Demographics\\\\Race\\\\\"]))\n",
    "print(\"Count race for diagnosed \",collec.Counter(demographics_diagnosed[\"\\\\00_Demographics\\\\Race\\\\\"]))\n",
    "print(\"Count race for undiagnosed \",collec.Counter(demographics_undiagnosed[\"\\\\00_Demographics\\\\Race\\\\\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistics for demographics\n",
    "demographics.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistics for demographics, for diagnosed patients\n",
    "demographics_diagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the statistics for demographics, for undiagnosed patients\n",
    "demographics_undiagnosed.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the gender count, for diagnosed and undiagnosed\n",
    "gender_count = demographics.groupby(\"\\\\00_Demographics\\\\Gender\\\\\")['Patient ID'].nunique()\n",
    "gender_count_d = demographics_diagnosed.groupby(\"\\\\00_Demographics\\\\Gender\\\\\")['Patient ID'].nunique()\n",
    "gender_count_nd = demographics_undiagnosed.groupby(\"\\\\00_Demographics\\\\Gender\\\\\")['Patient ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Gender count general\")\n",
    "print(gender_count)\n",
    "print(\"Gender count diagnosed\")\n",
    "print(gender_count_d)\n",
    "print(\"Gender count undiagnosed\")\n",
    "print(gender_count_nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Count of primary symptoms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the primary symptoms for patients with at least one phenotype, for diagnosed and undiagnosed\n",
    "primary_symptoms = primary_symptoms.loc[list(patient_phen)]\n",
    "primary_symptoms_d = primary_symptoms.loc[list_diagnosed_phen]\n",
    "primary_symptoms_nd = primary_symptoms.loc[list_undiagnosed_phen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the primary symptom count, for diagnosed and undiagnosed\n",
    "pscount = primary_symptoms.groupby(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")['Patient ID'].nunique()\n",
    "pscount_d = primary_symptoms_d.groupby(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")['Patient ID'].nunique()\n",
    "pscount_nd = primary_symptoms_nd.groupby(\"\\\\01_Primary symptom category reported by patient or caregiver\\\\\")['Patient ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Primary symptom count general\")\n",
    "print(pscount)\n",
    "print(\"Primary symptom count diagnosed\")\n",
    "print(pscount_d)\n",
    "print(\"Primary symptom count undiagnosed\")\n",
    "print(pscount_nd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Family history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get family history for patients with at least one phenotype, diagnosed or undiagnosed\n",
    "family_history = family_history.loc[list(patient_phen)]\n",
    "family_history_d = family_history.loc[list_diagnosed_phen]\n",
    "family_history_nd = family_history.loc[list_undiagnosed_phen]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get count of affected relatives, for diagnosed or undiagnosed\n",
    "fhcount = family_history.groupby(\"\\\\08_Family history (from PhenoTips)\\\\Affected Relatives\\\\\")['Patient ID'].nunique()\n",
    "fhcount_d = family_history_d.groupby(\"\\\\08_Family history (from PhenoTips)\\\\Affected Relatives\\\\\")['Patient ID'].nunique()\n",
    "fhcount_nd = family_history_nd.groupby(\"\\\\08_Family history (from PhenoTips)\\\\Affected Relatives\\\\\")['Patient ID'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Affected relatives count general\")\n",
    "print(fhcount)\n",
    "print(\"Affected relatives count diagnosed\")\n",
    "print(fhcount_d)\n",
    "print(\"Affected relatives count undiagnosed\")\n",
    "print(fhcount_nd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get natal history for patients with at least one phenotype\n",
    "natal_history = natal_history.loc[list(patient_phen)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace missing values by NaN\n",
    "natal_history = natal_history.replace(0, np.NaN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natal_history.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "natal_history.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the number of positive or negative occurrences for any given phenotype. Ex: if count_pos_phen[i]=3, \n",
    "# then there are three patients in the database that are positive for the phenotype header_phen[i]\n",
    "count_pos_phen,count_neg_phen=[0 for i in range(1,phenotypes.shape[1])],[0 for i in range(1,phenotypes.shape[1])]\n",
    "for i in range(1,phenotypes.shape[1]):\n",
    "    cts=phenotypes.iloc[:,i].value_counts()\n",
    "    keys=cts.keys().tolist()\n",
    "    for j in range(len(keys)):\n",
    "        if keys[j]==\"Positive\":\n",
    "            count_pos_phen[i-1]=cts[j]\n",
    "        elif keys[j]==\"Negative\":\n",
    "            count_neg_phen[i-1]=cts[j]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collec.Counter(family_history[\"\\\\08_Family history (from PhenoTips)\\\\Consanguinity\\\\\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_best_phenotypes_consang(patient_phen,family_history):\n",
    "    \"\"\"Gives the list of overrepresented phenotypes in the consanguineous community\n",
    "    Parameters : patient_phen: dictionary of list of positive and negative phenotypes for each patient\n",
    "                 family_history : dataframe with family history \n",
    "    Returns : dictionary with the count for positive or negative phenotypes of patients presenting such phenotype\n",
    "    Shows the ranked 10 best phenotypes, for positive and negative as well as the Mann Whitney U stats for difference in \n",
    "    distribution between the consanguineous and general community\n",
    "    \"\"\"\n",
    "    count_phenotype_consang={\"pos\": {}, \"neg\": {}}\n",
    "    csgcount=0\n",
    "    for patient in list(patient_phen):\n",
    "        consang = family_history.loc[patient][2]\n",
    "        if consang==True:\n",
    "            csgcount+=1\n",
    "            for phen_pos in patient_phen[patient][\"pos\"]:\n",
    "                if not(phen_pos in count_phenotype_consang[\"pos\"]):\n",
    "                    count_phenotype_consang[\"pos\"][phen_pos]=1\n",
    "                else:\n",
    "                    count_phenotype_consang[\"pos\"][phen_pos]+=1\n",
    "            for phen_neg in patient_phen[patient][\"neg\"]:\n",
    "                if not(phen_neg in count_phenotype_consang[\"neg\"]):\n",
    "                    count_phenotype_consang[\"neg\"][phen_neg]=1\n",
    "                else:\n",
    "                    count_phenotype_consang[\"neg\"][phen_neg]+=1\n",
    "    \n",
    "    phen_pos_list=list(count_phenotype_consang[\"pos\"])\n",
    "    val=[count_phenotype_consang[\"pos\"][phen] for phen in phen_pos_list]\n",
    "    indsort=np.argsort(val)[::-1]\n",
    "    phen_pos_list=np.array(phen_pos_list)[indsort][:18]\n",
    "    val=np.array(val)[indsort][:18]\n",
    "    print('Best positive phenotypes')\n",
    "    comp_mw_true=[]\n",
    "    for j,phen in enumerate(phen_pos_list):\n",
    "        for i,p in enumerate(list(phenotypes)[1:]):\n",
    "            if p.split(\"\\\\\")[-2]==phen:\n",
    "                print(phen,\"consang % \",val[j]/csgcount*100,\" general % \",count_pos_phen[i]/phenotypes.shape[0]*100)\n",
    "                comp_mw_true.append(count_pos_phen[i]/phenotypes.shape[0]*100)\n",
    "                break\n",
    "    print(\"Mann-Whitney pos : \")\n",
    "    print(\"Medians : \",np.median(np.multiply(val,100/csgcount)),np.median(comp_mw_true))\n",
    "    print(mannwhitneyu(np.multiply(val,100/csgcount),comp_mw_true))\n",
    "    phen_neg_list=list(count_phenotype_consang[\"neg\"])\n",
    "    val=[count_phenotype_consang[\"neg\"][phen] for phen in phen_neg_list]\n",
    "    indsort=np.argsort(val)[::-1]\n",
    "    phen_neg_list=np.array(phen_neg_list)[indsort][:10]\n",
    "    val=np.array(val)[indsort][:10]\n",
    "    print('Best negative phenotypes')\n",
    "    comp_mw_true=[]\n",
    "    for j,phen in enumerate(phen_neg_list):\n",
    "        for i,p in enumerate(list(phenotypes)[1:]):\n",
    "            if p.split(\"\\\\\")[-2]==phen:\n",
    "                print(phen,\"consang % \",val[j]/csgcount*100,\" general % \",count_neg_phen[i]/phenotypes.shape[0]*100)\n",
    "                comp_mw_true.append(count_neg_phen[i]/phenotypes.shape[0]*100)\n",
    "                break\n",
    "    print(\"Mann-Whitney neg : \")\n",
    "    print(\"Medians : \",np.median(np.multiply(val,100/csgcount)),np.median(comp_mw_true))\n",
    "    print(mannwhitneyu(np.multiply(val,100/csgcount),comp_mw_true))\n",
    "    print(\"How many consang ?\",csgcount)\n",
    "    return count_phenotype_consang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_phenotype_consang=get_best_phenotypes_consang(patient_phen,family_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mat_age is the maternal age without the NaN values\n",
    "mat_age=np.array(natal_history[\"\\\\09_Prenatal and perinatal history (from PhenoTips)\\\\Maternal Age\\\\\"])\n",
    "isnan_mat=np.isnan(mat_age)\n",
    "mat_age=mat_age[[not(isnan_mat[i]) for i in range(len(isnan_mat))]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# distribution of maternal age in the US in 2009 (cf. article)\n",
    "USA_dist = [3.1,6.9,24.4,28.2,23.1,11.5,2.8]\n",
    "tranches=[\"0-18\",\"18-19\",\"20-24\",\"24-29\",\"30-34\",\"34-39\",\">39\"]\n",
    "\n",
    "def distrib_age(mat_age, known_dist,tranches):\n",
    "    \"\"\"Shows the distribution of maternal age compared between UDN and the US in 2009\n",
    "    Parameters : mat_age: array of maternal age in the UDN database\n",
    "                 known_dist: list, known distribution of maternal age for age groups given in tranches\n",
    "                 tranches: list of str, age groups that correspond to the known distribution \n",
    "    Returns: dictionary with age distribution in the UDN \n",
    "    Shows a joint plot of UDN distribution and known distribution of maternal age\n",
    "    \"\"\"\n",
    "    count_age={}\n",
    "    for age in mat_age:\n",
    "        if age in count_age:\n",
    "            count_age[age]+=1\n",
    "        else:\n",
    "            count_age[age]=1\n",
    "    distrib_age=[0 for i in range(7)]\n",
    "    for age in count_age:\n",
    "        zone=-1\n",
    "        if age<18:\n",
    "            zone=0\n",
    "        elif age>=18 and age <=19:\n",
    "            zone=1\n",
    "        elif age>19 and age<=24:\n",
    "            zone=2\n",
    "        elif age>24 and age<=29:\n",
    "            zone=3\n",
    "        elif age>29 and age<=34:\n",
    "            zone=4\n",
    "        elif age>34 and age<=39:\n",
    "            zone=5\n",
    "        else:\n",
    "            zone=6\n",
    "        distrib_age[zone]+=count_age[age]/len(mat_age)*100\n",
    "    plt.figure(figsize=(20,20))\n",
    "    plt.rcParams['font.size'] = 40\n",
    "    plt.plot(tranches,distrib_age,'b',label=\"Distribution in UDN\")\n",
    "    plt.plot(tranches,known_dist,'r',label=\"Distribution in USA in 2009\")\n",
    "    plt.xlabel(\"Maternal age at birth\")\n",
    "    plt.ylabel(\"Distribution in UDN vs USA in 2009 (%)\")\n",
    "    plt.legend(bbox_to_anchor=(0., 1.02, 1., .102), loc=3,\n",
    "           ncol=2, mode=\"expand\", borderaxespad=0.)\n",
    "    plt.show()\n",
    "    return distrib_age\n",
    "\n",
    "dist_age_mat=distrib_age(mat_age,USA_dist,tranches)\n",
    "\n",
    "ttest_ind(dist_age_mat,USA_dist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Genomics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_gene_data(filename,var_or_gene):\n",
    "    \"\"\"Retrieve genetic data from a text file (formatted from JSON file)\n",
    "    Parameters: filename: string, name of the text file with the genetic information\n",
    "                var_or_gene: string, \"Var\" if variants of \"Gen\" if genes\n",
    "    Returns: genomic_data: dictionary with UDN ID as key and list of dictionaries as value, each dictionary containing \n",
    "                           information about genes or variants\n",
    "    \"\"\"\n",
    "    genomic_data={}\n",
    "    with open(filename,\"r\") as pg:\n",
    "        lines=pg.readlines()\n",
    "        for line in lines:\n",
    "            if line.split(\"<\")[0]==\"ID\":\n",
    "                pid=line.split(\" \")[3].split(\"\\n\")[0]\n",
    "                genomic_data[pid]=[]\n",
    "            elif line.split(\"<\")[0]==var_or_gene:\n",
    "                var=int(line.split(\" \")[1].split(\"\\n\")[0])\n",
    "                genomic_data[pid].append({})\n",
    "            else:\n",
    "                if not(len(line.split(\" \"))==1):\n",
    "                    genomic_data[pid][var][line.split(\" \")[0].split(\"\\n\")[0]]=line.split(\" \")[1].split(\"\\n\")[0]\n",
    "    print(len(genomic_data))\n",
    "    for patient in genomic_data:\n",
    "        if not(patient in list(patient_phen.keys())):\n",
    "            genomic_data=removekey(genomic_data,patient)\n",
    "    print(len(genomic_data))\n",
    "    return genomic_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "variants=get_gene_data(\"patient_genomic.txt\",\"Var\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genes=get_gene_data(\"patient_genes.txt\",\"Gene\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the list of patients that present a candidate gene or candidate variants\n",
    "list_patient_genes=list(genes.keys())\n",
    "list_patient_variants=list(variants.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Patients in both\", len([patient for patient in patient_phen if patient in list_patient_genes and patient in list_patient_variants]))\n",
    "print(\"Patients with only genes\", len([patient for patient in patient_phen if patient in list_patient_genes and not(patient in list_patient_variants)]))\n",
    "print(\"Patients with only variants\", len([patient for patient in patient_phen if not(patient in list_patient_genes) and patient in list_patient_variants]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count the number of solved cases for people with an indicated gene or an indicated variant\n",
    "print(\"Number of solved and unsolved cases for genes indicated : \",collec.Counter(status.loc[list(genes.keys())][\"\\\\13_Status\\\\\"]))\n",
    "print(\"Number of solved and unsolved cases for variants indicated : \",collec.Counter(status.loc[list(variants.keys())][\"\\\\13_Status\\\\\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dist_genomic(genomic_data,var_or_gene):\n",
    "    \"\"\"Get the distribution associated to genomic data for its characteristics\n",
    "    Parameters: genomic_data: dictionary, with UDN ID as key and list with dictionaries as value, dict contaning characteristics\n",
    "                              of the considered genomic data\n",
    "                var_or_gene: string, \"Var\" if variants, \"Gen\" otherwise\n",
    "    Returns: gene_effects: counter, with distribution of characteristics for selected genomic data\n",
    "    \"\"\"\n",
    "    gene_list=[]\n",
    "    for patient in genomic_data:\n",
    "        for i in range(len(genomic_data[patient])):\n",
    "            if var_or_gene==\"Var\":\n",
    "                if \"effect\" in list(genomic_data[patient][i].keys()) and \"gene\" in list(genomic_data[patient][i].keys()):\n",
    "                    gene_list.append([genomic_data[patient][i][\"gene\"],genomic_data[patient][i][\"effect\"]])\n",
    "                else:\n",
    "                    gene_list.append([genomic_data[patient][i][\"gene\"],\"NA\"])\n",
    "            elif var_or_gene==\"Gen\":\n",
    "                if \"status\" in list(genomic_data[patient][i].keys()) and \"gene\" in list(genomic_data[patient][i].keys()):\n",
    "                    gene_list.append([genomic_data[patient][i][\"gene\"],genomic_data[patient][i][\"status\"]])\n",
    "                else:\n",
    "                    gene_list.append([genomic_data[patient][i][\"gene\"],\"NA\"])  \n",
    "            else:\n",
    "                print(\"var_or_gene must be Var or Gen\")\n",
    "    gene_effects=collec.Counter(np.array(gene_list)[:,1])\n",
    "    return gene_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the count of mutation types for candidate variants\n",
    "gene_effects=get_dist_genomic(variants,\"Var\")\n",
    "gene_effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the distribution of gene status for candidate genes\n",
    "gene_status=get_dist_genomic(genes,\"Gen\")\n",
    "gene_status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_distribution_genomic_data(genomic_data,namefile,var_or_gene):\n",
    "    \"\"\"Show the distribution of counts of candidate genes or variant per patient in the UDN database\n",
    "    Parameters: genomic_data: dictionary, with UDN ID as key and list with dictionaries as value, dict contaning characteristics\n",
    "                              of the considered genomic data\n",
    "                namefile: string, file of the name to save the figure in \n",
    "                var_or_gene: string, \"variants\" if variants is considered, \"genes\" else\n",
    "    Returns: None\n",
    "    Show the distribution in a scatter plot and the counter, as well as total number of candidate genes/variants\n",
    "    \"\"\"\n",
    "    count_gene_per_patient=collec.Counter([len(genomic_data[patient]) for patient in genomic_data])\n",
    "    print(count_gene_per_patient)\n",
    "    X_gene=list(count_gene_per_patient)\n",
    "    Y_gene=[count_gene_per_patient[ct] for ct in X_gene]\n",
    "    print(\"Number of total candidate \",var_or_gene,\" : \",np.sum([X_gene[i]*Y_gene[i] for i in range(len(X_gene))]))\n",
    "    plt.plot(X_gene,Y_gene,\"o\")\n",
    "    plt.title(\"Distribution of number of candidate \"+var_or_gene+\" per patient\")\n",
    "    plt.xlabel(\"Number of candidate \"+var_or_gene)\n",
    "    plt.ylabel(\"Count of patients\")\n",
    "    plt.savefig(namefile,bbox_inches=\"tight\",dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_genomic_data(variants,\"Count_dist_var_per_pat.png\",\"variants\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_distribution_genomic_data(genes,\"Count_genes_per_pat.png\",\"genes\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code to search for inconsistent genes vs variants: only for XXX does the variants and genes not match \n",
    "\"\"\"for patient in genes:\n",
    "    if patient in variants:\n",
    "        list_gen=[genes[patient][i][\"id\"] for i in range(len(genes[patient]))]\n",
    "        list_var=[variants[patient][i][\"gene\"] for i in range(len(variants[patient]))]\n",
    "        sub=(list_gen if len(list_gen)<=len(list_var) else list_var)\n",
    "        supers=(list_var if len(list_gen)>=len(list_var) else list_gen)\n",
    "        if not(set(sub).issubset(supers)):\n",
    "            print(patient,\" genes \",list_gen,\" variants \",list_var)\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mannwhitneyu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All results are shown using the Mann Whitney U statistic. The closer to 0 the statistic, the more significantly different the distributions are -- this can also be assessed with the p value, if p<0.05 the distributions are significantly different"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Diagnosed vs undiagnosed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age at UDN Evaluation\")\n",
    "mannwhitneyu(np.array(demographics_diagnosed[\"\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\\"]),np.array(demographics_undiagnosed[\"\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Age at symptom onset\")\n",
    "mannwhitneyu(np.array(demographics_diagnosed[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"]),np.array(demographics_undiagnosed[\"\\\\00_Demographics\\\\Age at symptom onset in years\\\\\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get corresponding sample sizes (although the Mann Whitney U accepts different sample sizes, \n",
    "# this gives greater power, since we have the information)\n",
    "array_ps_d=np.array(pscount_d)\n",
    "array_ps_d=np.insert(array_ps_d,8,0)\n",
    "array_ps_d=np.insert(array_ps_d,12,0)\n",
    "array_ps_d=np.insert(array_ps_d,18,0)\n",
    "np.median(np.multiply(array_ps_d,1/len(list_diagnosed_phen))),np.median(np.multiply(np.array(pscount_nd),1/len(list_undiagnosed_phen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Primary symptoms\")\n",
    "mannwhitneyu(np.multiply(array_ps_d,1/len(list_diagnosed_phen)),np.multiply(np.array(pscount_nd),1/len(list_undiagnosed_phen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "array_cs_d=np.insert(np.array(cscount_d),7,0)\n",
    "np.median(np.multiply(array_cs_d,1/len(list_diagnosed_phen))),np.median(np.multiply(np.array(cscount_nd),1/len(list_undiagnosed_phen)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Clinical sites\")\n",
    "mannwhitneyu(np.multiply(array_cs_d,1/len(list_diagnosed_phen)),np.multiply(np.array(cscount_nd),1/len(list_undiagnosed_phen)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the index of unique phenotypes in the phenotype Dataframe\n",
    "mat_phen_ind=[]\n",
    "uniquep=[]\n",
    "for i,phen in enumerate(header_phen):\n",
    "    if not(phen.split(\"\\\\\")[-2] in uniquep):\n",
    "        mat_phen_ind.append(i)\n",
    "        uniquep.append(phen.split(\"\\\\\")[-2])\n",
    "len(mat_phen_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# take the patient ID column out of the phenotype dataframe\n",
    "matrix_phen=phenotypes.drop(\"Patient ID\",axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# transform the phenotype dataframe to obtain a matrix of unique phenotypes, with only patients that have been evaluated,\n",
    "# with 1 if the phenotype is positively present, 0 if negative or NaN\n",
    "mat_phen=matrix_phen.iloc[:,mat_phen_ind]\n",
    "mat_phen=mat_phen.loc[list(patient_phen.keys())]\n",
    "mat_phen=mat_phen.replace(to_replace={\"Positive\": 1, \"Negative\": 0, np.nan: 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The matrix is comprised of 1042 patients with at least 1 phenotype, and 3965 unique phenotypes\n",
    "mat_phen.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute the jaccard similarity matrix for the phenotypic matrix\n",
    "from sklearn.metrics.pairwise import pairwise_distances\n",
    "jac_sim_un = 1 - pairwise_distances(mat_phen, metric = \"jaccard\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def graph_of_patients_js(UDN_IDs,sim_matrix):\n",
    "    \"\"\"Constructs the graph of UDN patients using the similarity matrix computed: nodes are patients, edges between patient\n",
    "    i and j is proportional to the similarity between these two patients\n",
    "    Parameters: UDN_IDs: list of UDN IDs of patients to consider\n",
    "                sim_matrix: array, similarity matrix of pairwise similarity between each patient\n",
    "    Returns : G: networkx graph of UDN patients \n",
    "              pos: array, positions of nodes \n",
    "    \"\"\"\n",
    "    G= nx.Graph()\n",
    "    elist=[]\n",
    "    print(\"udnlen\",len(UDN_IDs))\n",
    "    print(\"cslen\",len(sim_matrix))\n",
    "    for i in range(sim_matrix.shape[0]):\n",
    "        G.add_node(UDN_IDs[i])\n",
    "        for j in range(i,sim_matrix.shape[1]):\n",
    "            elist.append((UDN_IDs[i],UDN_IDs[j],sim_matrix[i,j]))\n",
    "    G.add_weighted_edges_from(elist)\n",
    "    pos=nx.spring_layout(G,dim=2)\n",
    "    return G,pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_un,pos_un=graph_of_patients_js(list(patient_phen.keys()),jac_sim_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# writes the computed graph in a gml format, to be able to use Gephi to analyze it further\n",
    "nx.write_gml(graph_un,\"graph_un.gml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_clusters_community(graph):\n",
    "    \"\"\"Compute the clusters in a graph using Louvain's community detection method\n",
    "    Parameters : graph: networkx graph of UDN patients computed using the pairwise similarity between patients\n",
    "    Returns: clusters: dictionary with the cluster number as key and a list containing all the patients in the cluster\n",
    "                       as value\n",
    "    \"\"\"\n",
    "    partition = community_louvain.best_partition(graph)\n",
    "    print(\"Partition done\")\n",
    "    clusters={}\n",
    "    for node in partition.keys():\n",
    "        if not(partition[node] in clusters.keys()):\n",
    "            clusters[partition[node]]=[node]\n",
    "        else:\n",
    "            clusters[partition[node]].append(node)\n",
    "    count=0\n",
    "    for cluster in clusters.keys():\n",
    "        print(\"Length of cluster \",cluster,\":\",len(clusters[cluster]))\n",
    "        if len(clusters[cluster])==1:\n",
    "            count+=1\n",
    "    print(\"Number of clusters with only one patient (outliers) :\",count)\n",
    "    return clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_un=compute_clusters_community(graph_un)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the cluster compositions in a .txt format\n",
    "with open(\"clusters_un.txt\",\"w\") as clus:\n",
    "    for cluster in clusters_un:\n",
    "        clus.write(\"<!> Cluster \"+str(cluster)+\"\\n\")\n",
    "        for patient in clusters_un[cluster]:\n",
    "            clus.write(patient+\"\\n\")\n",
    "clus.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we compute the indices of clusters with more than 2 patients, the indices of pairs and the indices of groups with only 1\n",
    "ind_groups=[cluster for cluster in clusters_un if len(clusters_un[cluster])>2]\n",
    "ind_pairs=[cluster for cluster in clusters_un if len(clusters_un[cluster])==2]\n",
    "ind_outliers=[cluster for cluster in clusters_un if len(clusters_un[cluster])==1]\n",
    "ind_groups,ind_pairs,ind_outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pair analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are phenotypes in common between pairs; if not, prints \"Nothing in common\"; if so, prints the common phenotype\n",
    "for cluster in ind_pairs:\n",
    "    print(\"Cluster C\",cluster)\n",
    "    cmn=False\n",
    "    for phen in patient_phen[clusters_un[cluster][0]][\"pos\"]:\n",
    "        if phen in patient_phen[clusters_un[cluster][1]][\"pos\"]:\n",
    "            print(\"This phenotype in both patients: \",phen)\n",
    "            cmn=True\n",
    "    if not(cmn):\n",
    "        print(\"Nothing in common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shows the phenotypes for the two pairs that have phenotypes in common\n",
    "for cluster in [7,11]:\n",
    "    print(\"Cluster C\",cluster)\n",
    "    print(patient_phen[clusters_un[cluster][0]],patient_phen[clusters_un[cluster][1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cluster analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_diag_OR(clusters,clusters_ind,status):\n",
    "    \"\"\"Calculate the Odds Ratio for the probability of being diagnosed linked to being in a certain cluster\n",
    "    Parameters: clusters: dictionary with cluster number as key and list of patients in cluster as value\n",
    "                clusters_ind: list, indices of cluster to take into account \n",
    "                status: string, status of the patient (if patient's case is solved or not)\n",
    "    Returns: OR_diag: dictionary with cluster number as key and the Odds Ratio (OR) for each cluster\n",
    "    \"\"\"\n",
    "    count_diag_clusters={cluster: 0 for cluster in clusters_ind}\n",
    "    for cluster in clusters_ind:\n",
    "        for patient in clusters[cluster]:\n",
    "            if status.loc[patient][\"\\\\13_Status\\\\\"]==\"solved\":\n",
    "                count_diag_clusters[cluster]+=1\n",
    "    OR_diag,IC={},{}\n",
    "    def IC_func(sign,OR,a,b,c,d):\n",
    "        if sign==\"up\":\n",
    "            return np.exp(np.log(OR)+1.96*np.sqrt(1/a+1/b+1/c+1/d))\n",
    "        else:\n",
    "            return np.exp(np.log(OR)-1.96*np.sqrt(1/a+1/b+1/c+1/d))\n",
    "    for cluster in count_diag_clusters:\n",
    "        count_diag_notin=np.sum([count_diag_clusters[cl] for cl in clusters_ind if not(cl==cluster)])\n",
    "        OR_diag[cluster]=(count_diag_clusters[cluster]/count_diag_notin)/((len(clusters[cluster])-count_diag_clusters[cluster])/np.sum([len(clusters[cl])-count_diag_clusters[cl] for cl in clusters_ind]))\n",
    "        IC[cluster]={\"up\": IC_func(\"up\",OR_diag[cluster],count_diag_clusters[cluster],(len(clusters[cluster])-count_diag_clusters[cluster]),count_diag_notin,np.sum([len(clusters[cl])-count_diag_clusters[cl] for cl in clusters_ind]))\n",
    "                    ,\"low\": IC_func(\"low\",OR_diag[cluster],count_diag_clusters[cluster],(len(clusters[cluster])-count_diag_clusters[cluster]),count_diag_notin,np.sum([len(clusters[cl])-count_diag_clusters[cl] for cl in clusters_ind]))}\n",
    "    return OR_diag,IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OR_diag,IC=calculate_diag_OR(clusters_un,ind_groups,status)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Odds Ratio for clusters with more than 2 patients. If OR>1, a patient in the cluster is more likely to be diagnosed. The CI \n",
    "# is the confidence interval; if it does not span 1, then the OR is statistically significant\n",
    "OR_diag,IC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def phenotype_enrichment_analysis(patients_clustered,patient_phen,polarity_HPO):\n",
    "    \"\"\"Get the phenotypes shared by the most patients in the cluster according to polarity (positive or negative)\n",
    "    Parameters: patients_clustered: list of patients in the cluster \n",
    "                patient_phen: dictionary of unique phenotypes associated with each patient; key is patient, value is dictionary\n",
    "                with key \"pos\" or \"neg\" and value list of unique phenotypes with positive or negative association\n",
    "                polarity_HPO: string, \"pos\" or \"neg\", polarity wanted for the phenotype enrichment analysis\n",
    "    Returns: phen_ranked: list of best phenotypes ranked according to their representation in the cluster\n",
    "             values: list of proportion of patients presenting the phenotype in the phen_ranked same position (ex: values[i]\n",
    "             will have the represention of phenotype phen_ranked[i])\n",
    "    \"\"\"\n",
    "    phen_count={}\n",
    "    for patient in patients_clustered:\n",
    "        for phen in patient_phen[patient][polarity_HPO]:\n",
    "            if not(phen in phen_count):\n",
    "                phen_count[phen]=1/len(patients_clustered)\n",
    "            else:\n",
    "                phen_count[phen]+=1/len(patients_clustered)\n",
    "    phen_ranked=np.array([phen for phen in phen_count.keys()])\n",
    "    values=np.array([phen_count[phen] for phen in phen_ranked])\n",
    "    indrank=np.argsort(values)[::-1]\n",
    "    phen_ranked=phen_ranked[indrank]\n",
    "    values=values[indrank]\n",
    "    return phen_ranked,values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_HPO_count(patients_clustered,HPO_terms):\n",
    "    \"\"\"get the count of HPO terms for patients in the cluster, and the average\n",
    "    Parameters: patients_clustered: dictionary with cluster number as key and list of patients in the cluster as value\n",
    "                HPO_terms: dictionary with patient as key and count of HPO terms for the patient as value\n",
    "    Returns: HPO_cluster: dictionary with cluster number as key and list of HPO numbers for each patient in the cluster as value\n",
    "             avg_HPO_clusters: dictionary with cluster number as key and average number of HPO terms per patient as value\n",
    "    \"\"\"\n",
    "    HPO_cluster = {i: [] for i in patients_clustered.keys()}\n",
    "    for cluster in patients_clustered:\n",
    "        for patient in patients_clustered[cluster]:\n",
    "            HPO_cluster[cluster].append(HPO_terms[patient])\n",
    "    avg_HPO_clusters = {cluster: np.average(HPO_cluster[cluster]) for cluster in patients_clustered.keys()}\n",
    "    CI_HPO_clusters = {cluster: get_CI(HPO_cluster[cluster]) for cluster in patients_clustered.keys()}\n",
    "    return HPO_cluster,avg_HPO_clusters,CI_HPO_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the ranked positively and negatively associated phenotyeps for patients in each cluster (phen_ranked_pos \n",
    "# and phen_ranked_neg) as well as count of HPO terms per patient (and average) for each cluster\n",
    "# phen_ranked_pos (or _neg) is a dictionary with cluster number as key, and two arrays as value, one with the label\n",
    "# of phenotypes ranked to their composition, another with the composition of said phenotype in the cluster\n",
    "phen_ranked_pos,phen_ranked_neg={cluster: [] for cluster in ind_groups},{cluster: [] for cluster in ind_groups}\n",
    "HPO_count,avg_HPO_clusters,CI_HPO_clusters=get_HPO_count(clusters_un,HPO_terms)\n",
    "for cluster in ind_groups:\n",
    "    phen_ranked_pos[cluster]=phenotype_enrichment_analysis(clusters_un[cluster],patient_phen,\"pos\")\n",
    "    phen_ranked_neg[cluster]=phenotype_enrichment_analysis(clusters_un[cluster],patient_phen,\"neg\")\n",
    "avg_HPO_clusters,CI_HPO_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_best_phenotypes_clusters(phen_ranked,nb):\n",
    "    \"\"\"Shows the nb best ranked phenotypes for each cluster that has ranked phenotypes\n",
    "    Parameters: phen_ranked: dictionary with cluster number as key, two arrays as value, one with list of phenotypes \n",
    "                             ranked according to composition, second with composition of each phenotype\n",
    "                nb: int, number of best phenotypes to show\n",
    "    Returns: None\n",
    "    Shows the nb best phenotypes for each cluster with their composition\n",
    "    \"\"\"\n",
    "    for cluster in phen_ranked:\n",
    "        print(\"Cluster \",cluster)\n",
    "        print(\"Cluster len \",len(clusters_un[cluster]))\n",
    "        n=(nb if len(phen_ranked[cluster][0])>10 else len(phen_ranked[cluster][0]))\n",
    "        for i in range(n):\n",
    "            print(phen_ranked[cluster][0][i],phen_ranked[cluster][1][i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_best_phenotypes_clusters(phen_ranked_pos,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_best_phenotypes_clusters(phen_ranked_neg,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_phen(clusters_un,phen_ranked,figsize,vmin,vmax):\n",
    "    \"\"\"Displays heatmap of phenotype enrichment analysis for each cluster with analyzed composition\n",
    "    Parameters: clusters_un: dictionary with cluster number as key and list of patients in the cluster as value\n",
    "                phen_ranked: dictionary with cluster number as key, two arrays as value, one with list of phenotypes \n",
    "                             ranked according to composition, second with composition of each phenotype\n",
    "                figsize: int, size of the figure displayed\n",
    "                vmin: int, minimum value for the heatmap (here percentage)\n",
    "                vmax: int, max value for the heatmap (here percentage)\n",
    "    Returns: None\n",
    "    Shows the heatmap of phenotype enrichment analysis for each cluster\n",
    "    \"\"\"\n",
    "    cluster_list=[\"Cluster C\"+str(cluster)+\", size \"+str(len(clusters_un[cluster])) for cluster in ind_groups]\n",
    "    list_phen_max=[]\n",
    "    for cluster in ind_groups:\n",
    "        i,j=0,0\n",
    "        while j<5:\n",
    "            if not(phen_ranked[cluster][0][i]) in list_phen_max:\n",
    "                list_phen_max.append(phen_ranked[cluster][0][i])\n",
    "                j+=1\n",
    "            i+=1\n",
    "    heatmap_mat=[[] for i in range(len(list_phen_max))]\n",
    "    for i,phen in enumerate(list_phen_max):\n",
    "        for cluster in ind_groups:\n",
    "            if phen in phen_ranked[cluster][0]:\n",
    "                indphen=np.where(phen_ranked[cluster][0]==phen)[0][0]\n",
    "                heatmap_mat[i].append(phen_ranked[cluster][1][indphen]*100)\n",
    "            else:\n",
    "                heatmap_mat[i].append(0)\n",
    "    sns.set()\n",
    "    fig,ax=plt.subplots(figsize=(figsize,figsize))\n",
    "    sns.heatmap(heatmap_mat,cbar=True,cmap=\"YlGnBu\",xticklabels=cluster_list,yticklabels=list_phen_max,ax=ax,vmin=vmin,vmax=vmax)\n",
    "    plt.savefig(\"heatmap_all_clusters.png\",bbox_inches=\"tight\",dpi=350)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap for positive associations\n",
    "heatmap_phen(clusters_un,phen_ranked_pos,12,0,75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# heatmap for negative associations\n",
    "heatmap_phen(clusters_un,phen_ranked_neg,20,0,15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def metadata_collection(patients_clustered,metadata):\n",
    "    \"\"\"Get the metadata for each cluster \n",
    "    Parameters: patients_clustered: dictionary with cluster number as key and list of patients in the cluster as value\n",
    "                metadata: dataframe with metadata\n",
    "    Returns: metadata_clusters: dictionary with clusters as keys and dictionary as value, with key the metadata considered\n",
    "                                and list of values for patients in the cluster as value\n",
    "    \"\"\"\n",
    "    metadata_clusters={cl: {meta: [] for meta in list(metadata.columns)} for cl in patients_clustered.keys()}\n",
    "    for cl in patients_clustered:\n",
    "        for patient in patients_clustered[cl]:\n",
    "            for meta in list(metadata.columns)[1:]:\n",
    "                metadata_clusters[cl][meta].append(metadata.loc[patient][meta])\n",
    "    return metadata_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the demographics for the patient in the cluster \n",
    "demographics_coll=metadata_collection(clusters_un,demographics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the average and 95% CI for age at UDN evaluation\n",
    "for cluster in ind_groups:\n",
    "    lst=np.array(demographics_coll[cluster]['\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\'])\n",
    "    lst=lst[np.logical_not(np.isnan(lst))]\n",
    "    print(\"Cluster C\",cluster,\"Average age at UDN eval : \",np.average(lst),\" CI 95% : \",get_CI(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show the average and 95% CI for age at symptom onset in years\n",
    "for cluster in ind_groups:\n",
    "    lst=np.array(demographics_coll[cluster]['\\\\00_Demographics\\\\Age at symptom onset in years\\\\'])\n",
    "    lst=lst[np.logical_not(np.isnan(lst))]\n",
    "    print(\"Cluster C\",cluster,\"Average age at onset : \",np.average(lst),\" CI 95% : \",get_CI(lst))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_distrib(attribute):\n",
    "    \"\"\"Get a distribution for an attribute\n",
    "    Parameters: attribute: string, attribute we want the distribution of\n",
    "    Returns: counter of the collection library (distribution)\n",
    "    \"\"\"\n",
    "    counter={}\n",
    "    for cluster in demographics_coll:\n",
    "        dc=np.array(demographics_coll[cluster][attribute])\n",
    "        if type(dc[0])==np.float64:\n",
    "            dc=dc[np.logical_not(np.isnan(dc))]\n",
    "        counter[cluster]=collec.Counter(dc)\n",
    "    return counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_distrib=get_distrib('\\\\00_Demographics\\\\Gender\\\\')\n",
    "gender_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_eval_distrib=get_distrib('\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\')\n",
    "for key in age_eval_distrib:\n",
    "    print(age_eval_distrib[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_onset_distrib=get_distrib('\\\\00_Demographics\\\\Age at symptom onset in years\\\\')\n",
    "age_onset_distrib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "race_distrib=get_distrib('\\\\00_Demographics\\\\Race\\\\')\n",
    "race_distrib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ind_big_clusters=[0,2,3,4,5,6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the Kruskal Wallis for the distribution of HPO count between clusters\n",
    "kruskal(HPO_count[0],HPO_count[2],HPO_count[3],HPO_count[4],HPO_count[5],HPO_count[6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats_value(value_considered):\n",
    "    \"\"\"get the Kruskal Wallis U index and p-value for a type of demographics\n",
    "    Parameters: value_considered: string, type of demographics we want the KW U index and p-value\n",
    "    Returns: None\n",
    "    Prints the KW U index and p-value\n",
    "    \"\"\"\n",
    "    dc={i: [] for i in ind_big_clusters}\n",
    "    for i in ind_big_clusters:\n",
    "        dc[i]=np.array(demographics_coll[i][value_considered])\n",
    "        if type(dc[i][0])==np.float64:\n",
    "            dc[i]=dc[i][np.logical_not(np.isnan(dc[i]))]\n",
    "    print(kruskal(dc[0],dc[2],dc[3],dc[4],dc[5],dc[6]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KW test for Age at UDN evaluation\n",
    "get_stats_value('\\\\00_Demographics\\\\Age at UDN Evaluation (in years)\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KW test for Age at symptom onset\n",
    "get_stats_value('\\\\00_Demographics\\\\Age at symptom onset in years\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KW test for Gender\n",
    "get_stats_value('\\\\00_Demographics\\\\Gender\\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KW test for Race\n",
    "get_stats_value('\\\\00_Demographics\\\\Race\\\\')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Link between clusters and diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_diseases_from_XML(filename):\n",
    "    \"\"\"get the list of diseases in the Orphanet database by disease groups\n",
    "    Parameters: string, file name for the Orphanet xml file\n",
    "    Returns: list of diseases for the file name \n",
    "    \"\"\"\n",
    "    tree = ET.parse(filename)\n",
    "    root = tree.getroot()\n",
    "    dis=[]\n",
    "    for s in root.findall(\".//Disorder\"):\n",
    "        dis.append(s.find(\"Name\").text.lower())\n",
    "    return dis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get dictionary of all diseases in the Orphanet database, with disease group as key and list of diseases that belong\n",
    "# to said disease group\n",
    "all_diseases={}\n",
    "for file in os.listdir(\"xml_orphanet/\"):\n",
    "    if file.endswith(\".xml\"):\n",
    "        diseases=get_list_diseases_from_XML(\"xml_orphanet/\"+str(file))\n",
    "        all_diseases[file.split(\".\")[0]]=diseases\n",
    "all_diseases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the HPO mapping using the HPO database \n",
    "# mapping_HPO is a dictionary with HPO labels as key, dictionary as value, with keys id (value HPO number), key parent \n",
    "# (list of HPO numbers of n-1 parents), syn (possible label synonyms), xref (references to other classifications/ontologies)\n",
    "mapping_HPO={}\n",
    "with open(\"hpo.txt\",\"r+\") as hpo:\n",
    "    lines = hpo.readlines()\n",
    "    i=0\n",
    "    for i in range(len(lines)):\n",
    "        if lines[i].split(\":\")[0]==\"id\":\n",
    "            hpoid=lines[i].split(\" \")[1].split(\"\\n\")[0]\n",
    "            name=\"\"\n",
    "            for namestr in lines[i+1].split(\" \")[1:]:\n",
    "                name+=namestr+\" \"\n",
    "            name=name.split(\"\\n\")[0]\n",
    "            mapping_HPO[name]={\"id\": hpoid, \"xref\": [], \"parent\": [], \"syn\":[]}\n",
    "        if lines[i].split(\" \")[0]==\"xref:\":\n",
    "            mapping_HPO[name][\"xref\"].append(lines[i].split(\" \")[1].split(\"\\n\")[0])\n",
    "        if lines[i].split(\" \")[0]==\"is_a:\":\n",
    "            mapping_HPO[name][\"parent\"].append(lines[i].split(\" \")[1])\n",
    "        if lines[i].split(\" \")[0]==\"synonym:\":\n",
    "            namesyn=\"\"\n",
    "            for namestr in lines[i].split(\" \")[1:]:\n",
    "                namesyn+=namestr+\" \"\n",
    "            namesyn=namesyn.split(\"\\\"\")[1].split(\"'\")[0]\n",
    "            if len(namesyn.split(\"obsolete \"))>1:\n",
    "                namesyn=namesyn.split(\"obsolete \")[1]\n",
    "            mapping_HPO[name][\"syn\"].append(namesyn)\n",
    "mapping_HPO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_diseases_cl(clusters,diagnostics):\n",
    "    \"\"\"get the list of diseases diagnosed for patients in the clusters\n",
    "    Parameters: clusters: dictionary with cluster number as key and list of patients in the cluster as value\n",
    "                diagnostics: dataframe with the associated diagnostics for each patient\n",
    "    Returns: diseases_cl: dictionary with cluster number as key, dictionary as value, with patient ID as key, diagnosed\n",
    "                          illness as value\n",
    "    \"\"\"\n",
    "    diseases_cl={}\n",
    "    for cluster in clusters:\n",
    "        diseases_cl[cluster]={}\n",
    "        for patient in clusters[cluster]:\n",
    "            diag=diagnostics.loc[patient][\"\\\\14_Disorders (in OMIM, from PhenoTips)\\\\\"]\n",
    "            if type(diag)==float:\n",
    "                if not(np.isnan(diag)):\n",
    "                    diseases_cl[cluster][patient]=diag\n",
    "            else:\n",
    "                if not(diag==\"affected\"):\n",
    "                    diseases_cl[cluster][patient]=diag.lower()\n",
    "    return diseases_cl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diseases_cl=get_diseases_cl(clusters_un,diagnostics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OMIM_orpha_map(OMIM_diseases):\n",
    "    \"\"\"Get the mapping between OMIM database and Orphanet database (for a single cluster)\n",
    "    Parameters: OMIM_diseases: list of OMIM diseases labels we want the mapping for\n",
    "    Returns: ORPHA_OMIM: dictionary with OMIM disease label as key and Orphanet disease label as value\n",
    "    \"\"\"\n",
    "    ORPHA_OMIM={}\n",
    "    for dis in OMIM_diseases:\n",
    "        response = requests.get(\"https://api.omim.org/api/entry/search?search=\"+ dis +\"&start=0&limit=2&apiKey=rLnJSxMySW68Y9vB8m5clA&include=externalLinks\")\n",
    "        if len(response.text.split(\"<orphanetDiseases>\"))==1:\n",
    "            print(dis)\n",
    "        else:\n",
    "            ORPHA_OMIM[dis]=response.text.split(\"<orphanetDiseases>\")[1].split(\"</orphanetDiseases>\")[0].split(\";;\")[-1]\n",
    "    return ORPHA_OMIM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_OMIM_ORPHA_link(diseases_cl):\n",
    "    \"\"\"get the entire mapping between the OMIM database and Orphanet database (for all clusters)\n",
    "    Parameters: diseases_cl: dictionary with cluster number as key, dictionary as value, with patient ID as key and diagnosed\n",
    "                             illness as value\n",
    "    Returns: OMIM_ORPHA: dictionary with OMIM disease label as key and Orphanet diseases label as value\n",
    "    \"\"\"\n",
    "    disOMIM=[]\n",
    "    for cl in diseases_cl:\n",
    "        disOMIM+=[diseases_cl[cl][patient].lower() for patient in diseases_cl[cl]]\n",
    "    OMIM_ORPHA=get_OMIM_orpha_map(disOMIM)\n",
    "    return OMIM_ORPHA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OMIM_ORPHA=get_OMIM_ORPHA_link(diseases_cl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_disease_association_real(ind_groups,diseases_cl,all_diseases,OMIM_ORPHA):\n",
    "    \"\"\"get the disease associations for diagnosed diseases within the clusters\n",
    "    Parameter: ind_groups: list of indices of clusters to consider\n",
    "               diseases_cl: dictionary with cluster number as key, dictionary as value, with patient ID as key and diagnosed\n",
    "                            illness as value\n",
    "               all_diseases: dictionary with disease type as key, list of associated diseases as value\n",
    "               OMIM_ORPHA: dictionary, mapping between OMIM diseases (key) and Orphanet diseases (value)\n",
    "    Return: dg_associations_real: dictionary with cluster number as key, dictionary as value, with patient ID as key and\n",
    "                                  disease type associated as value\n",
    "    \"\"\"\n",
    "    dg_associations_real={}\n",
    "    for cluster in ind_groups:\n",
    "        dg_associations_real[cluster]={}\n",
    "        for patient in diseases_cl[cluster]:\n",
    "            dg_associations_real[cluster][patient]=[]\n",
    "            for distype in all_diseases:\n",
    "                if diseases_cl[cluster][patient] in OMIM_ORPHA:\n",
    "                    if OMIM_ORPHA[diseases_cl[cluster][patient]].lower() in all_diseases[distype]:\n",
    "                        dg_associations_real[cluster][patient].append(distype)\n",
    "    return dg_associations_real\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dg_associations_real=get_disease_association_real(ind_groups,diseases_cl,all_diseases,OMIM_ORPHA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_count_dg(dg_associations,all_diseases):\n",
    "    \"\"\"Get the count of disease groups found associated with patients in the cluster\n",
    "    Parameters: dg_associations: dictionary with cluster number as key, dictionary as value, with patient ID as key and\n",
    "                                  disease type associated as value\n",
    "                all_diseases: dictionary with disease type as key, list of associated diseases as value\n",
    "    Returns: count_dg: dictionary with cluster number as key, dictionary as value, with disease group as key and count of disease\n",
    "                        group \n",
    "    \"\"\"\n",
    "    count_dg={cluster: {} for cluster in patient_to_dg}\n",
    "    for cluster in dg_associations:\n",
    "        for patient in dg_associations[cluster]:\n",
    "            for dg in dg_associations[cluster][patient]:\n",
    "                if dg in count_dg[cluster]:\n",
    "                    count_dg[cluster][dg]+=1\n",
    "                else:\n",
    "                    count_dg[cluster][dg]=1\n",
    "    return count_dg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_dg_real=get_count_dg(dg_associations_real,all_diseases)\n",
    "# print the disease groups for each cluster ranked, along with the count\n",
    "for cluster in count_dg_real:\n",
    "    print(\"Cluster \",cluster)\n",
    "    list_dg=[]\n",
    "    for dg in count_dg_real[cluster]:\n",
    "        if not(dg=='rare_genetic_diseases'):\n",
    "            list_dg.append([dg,count_dg_real[cluster][dg]])\n",
    "    list_dg.sort(key = lambda x: x[1],reverse=True)\n",
    "    print(list_dg)\n",
    "    print(\"---------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def heatmap_real(count_dg_real,figsize,vmin,vmax):\n",
    "    \"\"\"Show the heatmap of cluster according to disease group composition\n",
    "    Parameters: count_dg_real: dictionary with cluster number as key, dictionary as value, with disease group as key and count of disease\n",
    "                               group\n",
    "                figsize: int, size of the figure\n",
    "                vmin: int, minimum value for the heatmap (here percentage)\n",
    "                vmax: int, max value for the heatmap (here percentage)\n",
    "    Returns: None\n",
    "    Shows the heatmap associated to the composition in disease group for each cluster\n",
    "    \"\"\"\n",
    "    type_disease={'rare_bone_diseases': 0, 'rare_skin_diseases': 1, 'rare_surgical_maxillofacial_diseases': 2, \n",
    "                  'rare_urogenital_diseases': 3, 'rare_neoplastic_diseases': 4, 'rare_surgical_thoracic_diseases': 5,\n",
    "                  'rare_cardiac_malformations': 6, 'rare_teratologic_disorders': 7, \n",
    "                  'rare_systemic_and_rheumatological_diseases': 8, 'rare_sucking_swallowing_disorders': 9, \n",
    "                  'rare_hepatic_diseases': 10, 'rare_immunological_diseases': 11, 'rare_endocrine_diseases': 12, \n",
    "                  'chromosomal_anomalies': 13, 'rare_abdominal_surgical_diseases': 14, 'rare_infertility': 15, \n",
    "                  'rare_allergic_disease': 16, 'rare_haematological_diseases': 17, 'rare_genetic_diseases': 18, \n",
    "                  'rare_respiratory_diseases': 19, 'rare_neurological_diseases': 20, 'rare_renal_diseases': 21, \n",
    "                  'rare_infectious_diseases': 22, 'rare_rheumatologic_diseases_of_childhood': 23, \n",
    "                  'rare_inborn_errors_of_metabolism': 24, 'rare_developmental_anomalies_during_embryogenesis': 25, \n",
    "                  'rare_otorhinolaryngological_diseases': 26, 'rare_odontological_diseases': 27, \n",
    "                  'rare_gastroenterological_diseases': 28, 'rare_cardiac_diseases': 29, \n",
    "                  'rare_gynaecological_and_obstetric_diseases': 30, 'rare_intoxications': 31, 'rare_eye_diseases': 32}\n",
    "    heatmap_mat=[[0 for i in range(len(count_dg_real))] for j in range(len(type_disease))]\n",
    "    cluster_list=np.sort([cluster for cluster in count_dg_real])\n",
    "    yl=[\"\" for i in range(len(type_disease))]\n",
    "    for dis in type_disease:\n",
    "        listname=dis.split(\".\")[0].split(\"_\")\n",
    "        name=\"\"\n",
    "        for string in listname:\n",
    "            name+=string+\" \"\n",
    "        yl[type_disease[dis]]=name\n",
    "    for cluster in count_dg_real:\n",
    "        sumcluster=np.sum([count_dg_real[cluster][dg] for dg in count_dg_real[cluster]])\n",
    "        for dg in count_dg_real[cluster]:\n",
    "            index=cluster_list.tolist().index(cluster)\n",
    "            heatmap_mat[type_disease[dg]][index]=count_dg_real[cluster][dg]/sumcluster*100\n",
    "    cluster_list=[\"Cluster C\"+str(cluster)+\", size \"+str(len(clusters_un[cluster])) for cluster in count_dg_real]\n",
    "    sns.set()\n",
    "    fig,ax=plt.subplots(figsize=(figsize,figsize))\n",
    "    ax=sns.heatmap(heatmap_mat,cbar=True,xticklabels=cluster_list,yticklabels=yl,vmin=vmin,vmax=vmax)\n",
    "    plt.xlabel(\"Clusters\")\n",
    "    plt.ylabel(\"Disease subgroup\")\n",
    "    plt.savefig(\"heatmap_disease_ass.png\",bbox_inches=\"tight\",dpi=500)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heatmap_real(count_dg_real,12,0,25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
